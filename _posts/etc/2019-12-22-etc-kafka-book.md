---
layout: post
title:  "카프카 책 정리"
date:   2019-12-22 13:00:00
author: bghgu
categories: etc
tags: [etc]
---

#### 들어가며
* 대용량, 대규모 메시지 데이터를 빠르게 처리하도록 개발된 메시징 플랫폼
* 빅데이터를 분석할 때 여러 스토리지와 분석 시스템에 데이터를 연결하기 위한 필수 도구로 인식되었다.
* 글로벌 기업들에서 데이터 파이프라인으로 매우 중요하게 사용되고 있다.

#### 카프카 탄생 배경
* 링크드인에서 처음 출발한 기술이다. 링크드인이 성장하면서 발생하는 내부 여러 이슈들을 해결하기 위해 탄생했다.
* 엔드 투 엔드(end-to-end) 연결 방식의 아키텍처는 많은 문제점이 있다.
1. 실시간 트랜잭션(OLTP) 처리와 비동기 처리가 동시에 이뤄지지만 통합된 전송 영역이 없으니 복잡도가 증가한다.
   * 문제를 발견하고 조치를 취하려면 이와 관련된 데이터 시스템을 확인해야 한다.
   * 장애나 운영체제 업그레이드, 하드웨어 증설과 같은 작업을 위해서도 역시 아주 많은 준비 시간이 필요하다.
2. 데이터 파이프라인 관리의 어려움이 있다.
   * 실시간 트랜잭션 데이터베이스, 아파치 하둡, 모니터링 시스템, 키-값 저장소 등 많은 데이터 시스템들이 있는데, 이 시스템에 저장된 동일한 데이터를 개발자나 개발 부서는 각기 다른 방법으로 파이프 라인을 만들고 유지하게 되었다.
   * 처음에는 각자의 목적에 맞게 만들어서 간편했지만, 시간이 지나면서 이 데이터 파이프라인들은 통합 데이터 분석을 위해 서로 연결되어야 하는 일들이 필연적으로 발생한다.
   * 하지만 각 파이프라인별로 데이터 포맷과 처리하는 방법들이 완전히 달라서 데이터 파이프라인은 확장하기 어렵다.
   * 이러한 데이터 파이프라인들을 조정하고 운영하는 것은 엄청난 노력이 필요했다.
   * 복잡성으로 인해 두 시스템 간의 데이터가 서로 달라져 데이터의 신뢰도마저 낮아졌다.
* 복잡도가 늘고 파이프라인이 파편화되면서 개발이 지연되고 데이터를 신뢰 할 수 없는 상황에 이르자, 모든 시스템으로 데이터를 전송할 수 있고, 실시간 처리도 가능하며, 급속도로 성장하는 서비스를 위해 확장이 용이한 시스템을 만들었다.
* 다음과 같은 목표를 가지고 카프카를 만들었다.
    * 프로듀서와 컨슈머의 분리
    * 메시징 시스템과 같이 영구 메시지 데이터를 여러 컨슈머에게 허용
    * 높은 처리량을 위한 메시지 최적화
    * 데이터가 증가함에 따라 스케일아웃이 가능한 시스템
* 사내에서 발생하는 모든 이벤트/데이터의 흐름을 중앙에서 관리하는 카프카를 적용한 결과, 서비스 아키텍처가 예전과 비교할 수 없을 정도로 매우 깔끔해졌다.
* 카프카가 전사 데이터 파이프라인으로 동작하기 때문에 모든 데이터 스토어와 여기서 발생하는 데이터/이벤트가 카프카를 중심으로 연결되어 있다.
* 기존 데이터 스토어가 그대로 있을 뿐만 아니라, 새로운 데이터 스토어가 들어와도 서로 카프카가 제공하는 표준 포맷으로 연결되어 있어서 데이터를 주고받는 데 부담이 없다.
* 그래서 더욱 상세하고 다양한 데이터를 분석해서 더 좋은 서비스를 제공할 수 있게 되었다.
* 이전에는 할 수 없었던 다양한 분석이 가능해져 신뢰성 높은 데이터 분석 뿐만 아니라 실시간 분석까지 할 수 있게 되어 서비스의 품질이 몇 단계 이상 높아질 수 있는 형태로 바뀌었다.
* 개발 입장에서도 이전에는 데이터 스토어 백엔드 관리와 백엔드에 따른 포맷, 별도의 앱 개발을 해야 했는데 이젠 카프카에만 데이터를 전달하면 나머지는 필요한 곳 또는 다른 서비스들이 각자 가져갈 수 있어서 본연의 업무에만 집중할 수 있게 되었다.
* 카프카를 메시지 전달의 중앙 플랫폼으로 두고 기업에서 필요한 모든 데이터 시스템뿐만 아니라 마이크로서비스, SaaS 서비스 등과 연결된 파이프라인을 만드는 것을 목표로 두고 개발되었다.

#### 메시징 시스템
* 

#### 카프카의 동작 방식과 원리
* 카프카는 기본적으로 메시징 서버로 동작한다.
* 메시지라고 불리는 데이터 단위를 보내는 측(퍼블리셔 publisher 또는 프로듀서 producer)에서 카프카에 토픽이라는 각각의 메시지 저장소에 저장하면, 가져가는 측(서브스크라이버 subscriber 또는 컨슈머 consumer)이 원하는 토픽에서 데이터를 가져가게 되어있다.
* 중앙에 메시징 시스템 서버를 두고 이렇게 메시지를 보내고(publish) 받는(subscribe) 형태의 통신을 펍/섭(pub/sub) 모델이라고 한다.

#### 일반적인 통신 모델
* 프로듀서와 컨슈머가 직접 통신하는 방식이다.
* 빠른 전송 속도와 전송 결과를 신속하게 알 수 있는 장점이 있다.
* 특정 개체에 장애가 발생한 경우 메시지를 보내는 쪽에서 대기 처리 등을 개별적으로 해주지 않으면 장애가 발생할 수 있다.
* 일반적 형태의 통신의 경우 통신에 참여하는 개체가 많아질수록 서로 일일이 다 연결을 하고 데이터를 전송해야 하기 때문에 확장성이 좋지 않다.
* 이런 형태의 단점을 극복하고자 나온 통신 모델이 펍/섭 모델이다.

#### 펍/섭(pub/sub) 모델
* 비동기 메시징 전송 방식이다.
* 바신자의 메시지에는 수신자가 정해져 있지 않은 상태로 발생(publish)한다.
* 구독(subscribe)을 신청한 수신자만이 정해진 메시지를 받을 수 있다.
* 또한 수신자는 발신자 정보가 없어도 원하는 메시지만을 수신할 수 있다.
* 이러한 구조 덕분에 다이나믹한 네트워크 토플로지와 높은 확장성을 확보할 수 있다.

#### 펍/섭(pub/sub) 모델 작동 방식
* 프로듀서가 메시지를 컨슈머에게 직접 전달하는게 아니라 중간의 메시징 시스템에 전달한다.
* 이때 메시지 데이터와 수신처 ID를 포함시킨다.
* 메시징 시스템의 교환기가 메시지의 수신처 ID값을 확인한 다음 컨슈머들의 큐에 전달된다.
* 컨슈머는 자신들의 큐를 모니터링하고 있다가, 큐에 메시지가 전달되면 이 값을 가져간다.
* 이렇게 구성할 경우 장점은 혹시나 개체가 하나 빠지거나 수신 불능 상태가 되었을 때에도, 메시징 시스템만 살아 있으면 프로듀서에서 전달된 메시지가 유실되지 않는다.
* 이 메시지는 불능 상태의 개체가 다시 회복되면 언제든지 다시 가져갈 수 있다.
* 각각의 개체가 다대다 통신을 하는것이 아니라 메시징 시스템을 중심으로 연결되기 때문에 확장성이 용이하다.
* 사용자나 어드민이 연결을 직접 관장하는 것이 아니라, 교환기의 룰에 의해서 데이터가 수신처의 큐에 정확하게 전달되므로 메시지 데이터 유실의 염려가 없다.
* 펍/섭의 단점은 직접 통신을 하지 않기 때문에 메시지가 정확하게 전달되었는지 확인하려면 코드가 좀 더 복잡해지고, 중간에 메시징 시스템이 있기 때문에 메시지 전달 속도가 빠르지 않다.
* 