---
layout: post
title:  "카프카 책 정리"
date:   2019-12-22 13:00:00
author: bghgu
categories: etc
tags: [etc]
---

#### 들어가며
* 대용량, 대규모 메시지 데이터를 빠르게 처리하도록 개발된 메시징 플랫폼
* 빅데이터를 분석할 때 여러 스토리지와 분석 시스템에 데이터를 연결하기 위한 필수 도구로 인식되었다.
* 글로벌 기업들에서 데이터 파이프라인으로 매우 중요하게 사용되고 있다.

#### 카프카 탄생 배경
* 링크드인에서 처음 출발한 기술이다. 링크드인이 성장하면서 발생하는 내부 여러 이슈들을 해결하기 위해 탄생했다.
* 엔드 투 엔드(end-to-end) 연결 방식의 아키텍처는 많은 문제점이 있다.
1. 실시간 트랜잭션(OLTP) 처리와 비동기 처리가 동시에 이뤄지지만 통합된 전송 영역이 없으니 복잡도가 증가한다.
   * 문제를 발견하고 조치를 취하려면 이와 관련된 데이터 시스템을 확인해야 한다.
   * 장애나 운영체제 업그레이드, 하드웨어 증설과 같은 작업을 위해서도 역시 아주 많은 준비 시간이 필요하다.
2. 데이터 파이프라인 관리의 어려움이 있다.
   * 실시간 트랜잭션 데이터베이스, 아파치 하둡, 모니터링 시스템, 키-값 저장소 등 많은 데이터 시스템들이 있는데, 이 시스템에 저장된 동일한 데이터를 개발자나 개발 부서는 각기 다른 방법으로 파이프 라인을 만들고 유지하게 되었다.
   * 처음에는 각자의 목적에 맞게 만들어서 간편했지만, 시간이 지나면서 이 데이터 파이프라인들은 통합 데이터 분석을 위해 서로 연결되어야 하는 일들이 필연적으로 발생한다.
   * 하지만 각 파이프라인별로 데이터 포맷과 처리하는 방법들이 완전히 달라서 데이터 파이프라인은 확장하기 어렵다.
   * 이러한 데이터 파이프라인들을 조정하고 운영하는 것은 엄청난 노력이 필요했다.
   * 복잡성으로 인해 두 시스템 간의 데이터가 서로 달라져 데이터의 신뢰도마저 낮아졌다.
* 복잡도가 늘고 파이프라인이 파편화되면서 개발이 지연되고 데이터를 신뢰 할 수 없는 상황에 이르자, 모든 시스템으로 데이터를 전송할 수 있고, 실시간 처리도 가능하며, 급속도로 성장하는 서비스를 위해 확장이 용이한 시스템을 만들었다.
* 다음과 같은 목표를 가지고 카프카를 만들었다.
    * 프로듀서와 컨슈머의 분리
    * 메시징 시스템과 같이 영구 메시지 데이터를 여러 컨슈머에게 허용
    * 높은 처리량을 위한 메시지 최적화
    * 데이터가 증가함에 따라 스케일아웃이 가능한 시스템
* 사내에서 발생하는 모든 이벤트/데이터의 흐름을 중앙에서 관리하는 카프카를 적용한 결과, 서비스 아키텍처가 예전과 비교할 수 없을 정도로 매우 깔끔해졌다.
* 카프카가 전사 데이터 파이프라인으로 동작하기 때문에 모든 데이터 스토어와 여기서 발생하는 데이터/이벤트가 카프카를 중심으로 연결되어 있다.
* 기존 데이터 스토어가 그대로 있을 뿐만 아니라, 새로운 데이터 스토어가 들어와도 서로 카프카가 제공하는 표준 포맷으로 연결되어 있어서 데이터를 주고받는 데 부담이 없다.
* 그래서 더욱 상세하고 다양한 데이터를 분석해서 더 좋은 서비스를 제공할 수 있게 되었다.
* 이전에는 할 수 없었던 다양한 분석이 가능해져 신뢰성 높은 데이터 분석 뿐만 아니라 실시간 분석까지 할 수 있게 되어 서비스의 품질이 몇 단계 이상 높아질 수 있는 형태로 바뀌었다.
* 개발 입장에서도 이전에는 데이터 스토어 백엔드 관리와 백엔드에 따른 포맷, 별도의 앱 개발을 해야 했는데 이젠 카프카에만 데이터를 전달하면 나머지는 필요한 곳 또는 다른 서비스들이 각자 가져갈 수 있어서 본연의 업무에만 집중할 수 있게 되었다.
* 카프카를 메시지 전달의 중앙 플랫폼으로 두고 기업에서 필요한 모든 데이터 시스템뿐만 아니라 마이크로서비스, SaaS 서비스 등과 연결된 파이프라인을 만드는 것을 목표로 두고 개발되었다.

#### 메시징 시스템
* 

#### 카프카의 동작 방식과 원리
* 카프카는 기본적으로 메시징 서버로 동작한다.
* 메시지라고 불리는 데이터 단위를 보내는 측(퍼블리셔 publisher 또는 프로듀서 producer)에서 카프카에 토픽이라는 각각의 메시지 저장소에 저장하면, 가져가는 측(서브스크라이버 subscriber 또는 컨슈머 consumer)이 원하는 토픽에서 데이터를 가져가게 되어있다.
* 중앙에 메시징 시스템 서버를 두고 이렇게 메시지를 보내고(publish) 받는(subscribe) 형태의 통신을 펍/섭(pub/sub) 모델이라고 한다.

#### 일반적인 통신 모델
* 프로듀서와 컨슈머가 직접 통신하는 방식이다.
* 빠른 전송 속도와 전송 결과를 신속하게 알 수 있는 장점이 있다.
* 특정 개체에 장애가 발생한 경우 메시지를 보내는 쪽에서 대기 처리 등을 개별적으로 해주지 않으면 장애가 발생할 수 있다.
* 일반적 형태의 통신의 경우 통신에 참여하는 개체가 많아질수록 서로 일일이 다 연결을 하고 데이터를 전송해야 하기 때문에 확장성이 좋지 않다.
* 이런 형태의 단점을 극복하고자 나온 통신 모델이 펍/섭 모델이다.

#### 펍/섭(pub/sub) 모델
* 비동기 메시징 전송 방식이다.
* 바신자의 메시지에는 수신자가 정해져 있지 않은 상태로 발생(publish)한다.
* 구독(subscribe)을 신청한 수신자만이 정해진 메시지를 받을 수 있다.
* 또한 수신자는 발신자 정보가 없어도 원하는 메시지만을 수신할 수 있다.
* 이러한 구조 덕분에 다이나믹한 네트워크 토플로지와 높은 확장성을 확보할 수 있다.

#### 펍/섭(pub/sub) 모델 작동 방식
* 프로듀서가 메시지를 컨슈머에게 직접 전달하는게 아니라 중간의 메시징 시스템에 전달한다.
* 이때 메시지 데이터와 수신처 ID를 포함시킨다.
* 메시징 시스템의 교환기가 메시지의 수신처 ID값을 확인한 다음 컨슈머들의 큐에 전달된다.
* 컨슈머는 자신들의 큐를 모니터링하고 있다가, 큐에 메시지가 전달되면 이 값을 가져간다.
* 이렇게 구성할 경우 장점은 혹시나 개체가 하나 빠지거나 수신 불능 상태가 되었을 때에도, 메시징 시스템만 살아 있으면 프로듀서에서 전달된 메시지가 유실되지 않는다.
* 이 메시지는 불능 상태의 개체가 다시 회복되면 언제든지 다시 가져갈 수 있다.
* 각각의 개체가 다대다 통신을 하는것이 아니라 메시징 시스템을 중심으로 연결되기 때문에 확장성이 용이하다.
* 사용자나 어드민이 연결을 직접 관장하는 것이 아니라, 교환기의 룰에 의해서 데이터가 수신처의 큐에 정확하게 전달되므로 메시지 데이터 유실의 염려가 없다.
* 펍/섭의 단점은 직접 통신을 하지 않기 때문에 메시지가 정확하게 전달되었는지 확인하려면 코드가 좀 더 복잡해지고, 중간에 메시징 시스템이 있기 때문에 메시지 전달 속도가 빠르지 않다.

#### 
* 기존 시스템을 이용하는 펍/섭 모델은 대규모 데이터를 메시징 시스템에 전달하기보다는 간단한 이벤트를 서버로 전송하는데 주로 사용되었다.
* 왜냐하면 메시징 시스템 내부의 교환기의 부하, 각 컨슈머들의 큐 관리, 큐에 전달되고 가져가는 메시지의 정합성, 전달 결과를 정확하게 관리하기 위한 내부 프로세스가 아주 다양하고 복잡하기 때문이다.
* 즉 기존의 메시징 시스템은 메시지의 보관, 교환, 전달 과정에서 신뢰성을 보장하는 것에 중점을 맞췄기 때문에 속도와 용량은 그렇게 중요하지 않았다.
* 그래서 회사나 조직 그리고 시스템 내의 데이터를 모으고 전달하기 위해서는 메시징 시스템이 절실하게 필요함에도 불구하고, 이것을 실제로 만드는 데는 항상 성능이 문제가 되어서 일부 컴포넌트나 원격 통신밖에 적용되지 못했다.
* 카프카는 메시징 시스템이 지닌 성능의 단점을 극복하기 위해, 메시지 교환 전달의 신뢰성 관리를 프로듀서와 컨슈머 쪽으로 넘기고, 부하가 많이 걸리는 교환기 기능 역시 컨슈머가 만들 수 잇게 함으로써 메시징 시스템 내에서의 작업량은 줄이고 이렇게 절약한 작업량을 메시징 전달 성능에 집중시켜서 고성능 메시징 시스템을 만들어냈다.

#### 카프카의 메시지 전달 순서
1. 프로듀서는 새로운 메시지를 카프카로 보낸다.
2. 프로듀서가 보낸 메시지는 카프카에 컨슈머 큐(토픽)에 도착해 저장된다.
3. 컨슈머는 카프카 서버에 접속하여 새로운 메시지를 가져간다.

#### 카프카 특징
* 카프카 역시 기존 메시징 시스템과 동일한 비동기 시스템이다.
* 프로듀서는 컨슈머와 관계없이 새로운 메시지를 카프카로 전송하고, 컨슈머 역시 프로듀서와 관계없이 카프카에서 새로운 메시지를 가져온다.
* 프로듀서와 컨슈머는 각자의 역할이 정확히 구분되어 있다.
* 카프카에서도 수많은 메시지들이 저장되고, 그 메시지들은 토픽이라는 식별자를 이용해 토픽 단위로 저장되고 있다.
* 비동기 기반으로 메시지를 전달하는 대표적인 솔루션이 메시지 큐 솔루션이다.

#### 카프카의 특징

##### 프로듀서와 컨슈머의 분리
* 링크드인에서는 메트릭 수집 방식을 폴링 방식으로 구현된 시스템을 사용했고, 메트릭 수집이 늦어지는 경우가 발생하면서 수집이나 처리 시간이 너무 늦어지는 문제점이 발견되었다.
* 이에 대한 해결 방법으로 데이터를 보내는 역할과 받는 역할을 완벽하게 분리하기를 원했다.
* 카프카는 메시징 전송 방식 중 메시지를 보내는 역할과 받는 역할이 완벽하게 분리된 펍/섭 방식을 적용했다.
* 펍/섭 방식인 카프카를 중앙에 놓으면 한눈에 보기에도 구조가 매우 단순해진다.
* 각각의 서비스들은 모니터링이나 분석 시스템의 상태 유무와 관계없이 카프카로 메시지를 보내는 역할만 하면 되고, 마친가지로 모니터링이나 분석 시스템들도 서비스 서버들의 상태 유무와 관계없이 카프카에 저장되어 있는 메시지만 가져오면 된다.
* 이렇게 각자의 역할이 완벽하게 분리되면서, 어느 한쪽 시스템에서 문제가 발생하더라도 연쇄작용이 발생할 확률은 매우 낮다.
* 또한 웹 서버가 추가되더라도 카프카로만 보내면 되기 때문에 서버 추가에 대한 부담도 줄일 수 있는 장점이 있다.

##### 멀티 프로듀서, 멀티 컨슈머
* 카프카는 하나의 토픽에 여러 프로듀서 또는 컨슈머들이 접근 가능한 구조로 되어있다.
* 하나의 프로듀서가 하나의 토픽에만 메시지를 보내는 것이 아니라, 하나 또는 하나 이상의 토픽으로 메시지를 보낼 수 있다.
* 컨슈머 역시 하나의 토픽에서만 메시지를 가져오는 것이 아니라, 하나 또는 하나 이상의 토픽으로부터 메시지를 가져올 수 있다.
* 멀티 기능은 데이터 분석 및 처리 프로세스에서 하나의 데이터를 다양한 용도로 사용하는 요구가 많아지기 시작했고, 이러한 요구 사항들을 손쉽게 충족할 수 있다.
* 멀티 프로듀서와 컨슈머를 구성할 수 있기 때문에 카프카는 중앙 집중형 구조로 구성할 수 있게 되었다.

##### 디스크에 메시지 저장
* 카프카가 기존의 메시징 시스템과 가장 다른 특징 중 하나는 바로 디스크에 메시지를 저장하고 유지하는 것이다.
* 일반적인 메시징 시스템들은 컨슈머가 메시지를 읽어가면 큐에서 바로 메시지를 삭제한다.
* 카프카는 컨슈머가 메시지를 읽어 가더라도 정해져 있는 보관 주기 동안 디스크에 메시지를 저장해둔다.
* 트래픽이 일시적으로 폭주해 컨슈머의 처리가 늦어지더라도 카프카의 디스크에 안전하게 보관되어 있기 때문에, 컨슈머는 메시지 손실 없이 메시지를 가져갈 수 있다.
* 멀티 컨슈머도 카프카에 메시지들이 디스크로 저장되어 있기 때문에 가능한 것이다.
* 컨슈머에 버그가 있어 오류가 발생했다면, 컨슈머를 잠시 중단하고 버그를 찾아 해결한 후 컨슈머를 다시 실행할 수 있다.
* 이러한 방법으로 작업하더라도 메시지가 디스크에 저장되어 있기 때문에 메시지 손실 없이 작업이 가능하다.

##### 확장성
* 카프카는 확장이 매우 용이하도록 설계되어 있다.
* 하나의 카프카 클러스터는 3대의 브로커로 시작해 수십 대의 브로커로 확장 가능하다.
* 확장 작업은 카프카 서비스의 중단 없이 온라인 상태에서 작업이 가능하다.
* 최초 카프카 클러스터 구성시 적은 수로 시작하더라도 이후 트래픽 및 사용량 증가로 클러스터를 확장하는 작업은 매우 간단할 뿐만 아니라, 큰 부담 없이 할 수 있다.

##### 높은 성능
* 카프카는 매우 높은 성능을 목표로 탄생한 애플리케이션이다.
* 고성능을 유지하기 위해 카프카는 내부적으로 분산 처리, 배치 처리 등 다양한 기법을 사용하고 있습니다.
  
#### 카프카의 용어 정리
* 카프카(Kafka) : 아파치 프로젝트 애플리케이션 이름이다. 클러스터 구성이 가능하며, 카프카 클러스라고 부른다.
* 브로커(Broker) : 카프카 애플리케이션이 설치되어 있는 서버 또는 노드를 말한다.
* 토픽(Topic) : 프로듀서와 컨슈머들이 카프카로 보낸 자신들의 메시지를 구분하기 위한 네임으로 사용한다. 많은 수의 프로듀서, 컨슈머들이 동일한 카프카를 이용하게 된다면, 메시지들이 서로 뒤섞여 각자 원하는 메시지를 얻기가 어렵게 된다. 그래서 토픽이라는 이름으로 구분하여 사용하게 된다.
* 파티션(Partition) : 병렬처리가 가능하도록 토픽을 나눌 수 있고, 많은 양의 메시지 처리를 위해 파티션의 수를 늘려줄 수 있다.
* 프로듀서(Producer) : 메시지를 생산하여 브로커의 토픽 이름으로 보내는 서버 또는 애플리케이션 등을 말한다.
* 컨슈머(Consumer) : 브로커의 토픽 이름으로 저장된 메시지를 가져가는 서버 또는 애플리케이션 등을 말한다.

#### 카프카의 확장과 발전
* 카프카를 통한 고성능의 펍/섭 모델이 가능해지면서 2000년대 초에 등장했던 서비스 기반 아키텍처(SOA, Service Oriented Architecture)의 핵심 구성요소 중 하나인 엔터프라이즈 서비스 버스(ESB, Enterprise Service Bus)를 쉽게 구현할 수 있게 되었습니다.
* SOA는 업무를 서비스라는 단위로 쪼개고, 각 서비스 간의 연결은 ESB를 통해 연결한다는 철학을 지향했다.
* ESB의 특징
    * 다양한 시스템과 연동하기 위한 멀티 프로토콜과 데이터 타입 지원
    * 느슨한 결합(Loosely coupled)을 위한 메시지 큐 지원
    * 정기적으로 데이터를 가져오는 대신 이벤트 기반(Event Driven) 통신 지향
* 카프카를 통해 ESB, 메시지 버스, 이벤트 버스 등과 같이 기업 내 데이터 흐름을 중앙에서 관리하는 많은 사례들이 생겨나고 있다.
* 현재는 기업 내 데이터 버스로뿐만 아니라 플러그인을 통해 외부 데이터를 가져와서 기업 내에서 활용할 수 있게 한다.
* 회사 내의 기존 메시징 시스템도 브릿지를 연결해서 사용하는 형태로 발전했다.
* 퍼블릭 클라우드와 같이 기업 외부에 있는 데이터 센터의 로깅/미터링/이벤트 데이터를 연결해서 가지고 올 수 있게 해서, 말 그대로 필요한 모든 데이터가 연결되어 서로 가져갈 수 있는 형태로 발전하고 있다.
* 마침내 카프카는 빅데이터 분석과 머신러닝 플랫폼을 만드는 데 아주 중요한 요소로 자리잡게 되었다.
* 이제는 강력한 메시지 전달 능력을 바탕으로, 단순히 메시징을 연결해주는 역할을 넘어서 실제로 실시간 분석까지 할 수 있는 카프카 스트림즈, KSQL 등 분석 시스템으로 진화하면서 말 그대로 메시징 플랫폼의 최강자가 되어 가고 있다.
* 기존에 아파치 스톰(Storm)이나 스파크(Spark)로 구성된 실시간 분석 플랫폼에 하둡을 활용한 배치 분석 플랫폼과도 연결할 수 있다.
* 다만, 스파크나 스톰은 대규모 시스템을 관리해줄 엔지니어가 별도로 있어야 하는데, 이런 단점을 극복하기 위해서 간단히 스트림 처리 앱을 개발할 수 있는 카프카 스트림즈와 SQL기반으로 데이터를 분석할 수 있게 해주는 KSQL을 통해 실시간 데이터 분석에 있어서도 주요한 부분을 담당하도록 발전하고 있다.
* 오늘날 카프카는 단순한 메시지 큐의 기능을 넘어 많은 기업의 비즈니스 확장 요구에 맞춰 기업 내 중요 시스템 중의 하나로 널리 사용되고 있다.

#### Zookeeper 주키퍼
* 현재까지의 카프카 버전에서는 오프셋 정보를 주키퍼와 카프카 양쪽에 저장할 수 있지만, 향후 주키퍼에 오프셋을 저장하는 기능은 사라질 예정이다.
* 주키퍼는 컨슈머와 통신하는 부분 외에도 카프카와 직접 통신을 하면서, 카프카의 메타데이터 정보를 주키퍼에 저장하고, 카프카의 상태관리 등의 목적으로 주키퍼를 이용한다.
* 카프카는 주키퍼와 긴밀하게 통신하기 때문에 주키퍼 사용이 필수 조건이다.
* 주키퍼는 카프카 패키지에 포함되어 있는 주키퍼를 사용할 수도 있고, 주키퍼 역시 아파치 오픈소스 중 하나이므로 별개의 주키퍼를 내려받아 사용할 수 있다.
* 많은 애플리케이션이 부하 분산 및 확장이 용이한 분산 애플리케이션으로 개발되고 있다. 하지만 이러한 분산 애플리케이션을 사용하게 되면, 분산 애플리케이션 관리를 위한 안정적인 코디네이션 애플리케이션이 추가로 필요하게 된다. 분산 애플리케이션을 개발하면서 동시에 코디네이션 애플리케이션도 개발하다 보면, 코디네이션 애플리케이션을 위한 추가적인 개발 리소스가 필요하게 되므로, 이미 안정적인 코디네이션 서비스로 검증된 주키퍼를 많이 사용한다.
* 주키퍼는 본래 하둡(Hadoop)의 서브 프로젝트 중 하나였다. 대용량 분산 처리 애플리케이션인 하둡은 중앙에서 분산 애플리케이션을 관리하는 코디네이션 애플리케이션이 필요했기에 서브 프로젝트로서 주키퍼 개발 작업을 진행하고 있었다.
* 카프카는 분산 애플리케이션의 한 종류로서 주키퍼를 코디네이션 로직으로 이용하고 있다.
* 주키퍼는 분산 애플리케이션을 위한 코디네이션 시스템이다.
* 분산 애플리케이션이 안정적인 서비스를 할 수 있도록 분산되어 있는 각 애플리케이션의 정보를 중앙에 집중하고 구성 관리, 그룹 관리 네이밍, 동기화 등의 서비스를 제공한다.
* 주키퍼는 서버 여러 대를 앙상블(클러스터)로 구성하고, 분산 애플리케이션들이 각각 클라이언트가 되어 주키퍼 서버들과 커넥션을 맺은 후 상태 정보 등을 주고받게 된다.
* 상태 정보들은 주키퍼의 지노드(znode)라 불리는 곳에 키-값(key-value) 형태로 저장하고, 지노드에 키-값이 저장된 것을 이용하여 분산 애플리케이션들은 서로 데이터를 주고 받게 된다.
* 주키퍼에서 사용되는 지노드는 데이터를 저장하기 위한 공간 이름을 말하는 것으로, 일반 컴퓨터의 파일이나 폴더 개념이라고 볼 수 있다.
* 지노드에 저장하는 데이터 크기는 바이트 에서 킬로바이트 정도로 매우 작으며, 지노드는 우리가 알고 있는 일반적인 디렉토리와 비슷한 형태로서 자식노드를 가지고 있는 계층형 구조로 구성되어 있다.
* 최상위 경로는 /이고 그 하위 경로로 노드이름(app1, app2...)등을 가진다. /app1, /app2 로 표현된다.
* 주키퍼의 각 지노드는 데이터 변경 등에 대한 유효성 검사 등을 위해 버전 번호를 관리하게 되며, 지노드의 데이터가 변경될 때마다 지노드의 버전 번호가 증가한다.
* 저장용으로 설계된 일반적인 파일 시스템과 달리 주키퍼에 저장되는 데이터는 모두 메모리에 저장되어 처리량이 매우 크고 속도 또한 빠르다.
* 주키퍼는 좀 더 신뢰성 있는 서비스를 위해 앙상블(클러스터)이라는 호스트 세트를 구성할 수 있다.
* 앙상블로 구성되어 있는 주키퍼는 과반수 방식에 따라 살아있는 노드 수가 과반수 이상 유지된다면, 지속적인 서비스가 가능하게 된다.
* 주키퍼 앙상블을 3대로 구성했을 때, 3의 과반수 이상은 2이므로 1대의 노드가 다운되더라도 지속적으로 서비스할 수 있다.
* 만약 2대의 노드가 다운되면 살아 있는 노드가 과반수 2보다 적기 때문에 서비스 장애 상태에 빠지게 된다.
* 앙상블 구성의 숫자가 많을수록 과반수 역시 커지므로 꽤 많은 노드의 수에서 장애가 발생해도 끊김없는 서비스를 제공할 수 있다.
* 주키퍼는 애플리케이션에서 별도의 디렉토리를 사용한다. 이 디렉토리에는 지노드의 복사본인 스냅샵과 트랜잭션 로그들이 저장된다.
* 지노드에 변경사항이 발생하면, 이러한 변경사항은 트랜잭션 로그에 추가된다. 그리고 로그가 어느 정도 커지면, 현재 모든 지노드의 상태 스냅샷이 파일시스템에 저장된다. 이 스냅샷은 모든 이전 로그들을 대체한다.
* 중요한 디렉토리이기 때문에 설치 경로와는 다른 경로로 설정하는 것이 바람직하다.

#### 카프카 설치
* 클러스터 구성을 할 수 있는 분산 애플리케이션의 한 종류인 카프카는 클러스터를 구성하는 서버 대수를 정해야 한다.
* 다만, 분산 애플리케이션이라는 면에서 보면 주키퍼와 동일하지만 클러스터가 운영되는 방식은 다르다.
* 과반수 방식으로 운영되어 홀수로 서버를 구성해야 하는 주키퍼와는 다르게, 카프카 클러스터는 홀수 운영 구성을 하지 않아도 된다.
* 주키퍼가 장애가 발생해서 코디네이션 역할을 하지 못하는 경우가 되면 카프카 클러스터에는 문제가 없더라도 주키퍼와 통신이 되지 않기 때문에 카프카 역시 장애 상황에 놓이게 된다.
* 따라서 주키퍼와 카프카는 동일한 서버가 아닌 별도의 주키퍼 서버와 별도의 카프카 서버로 구성하기를 권장한다.

#### 카프카의 주키퍼 설정에 따른 장애 시나리오
* ㄴ

#### 카프카 디자인의 특징
* 카프카 개발팀은 데이터 처리량이 많은 대규모 기업들에서 모든 실시간 데이터 피드를 효율적으로 처리하는 통합 플랫폼의 역할을 카프카가 수행해낼 수 있도록 설계하기 위해서 광범위한 이용 사례에 대한 고민을 많이 했다.
* 실시간 로그 집계와 같은 대용량의 실시간 데이터 처리를 위해서는 애플리케이션의 처리량이 높아야 한다.
* 카프카에서는 대용량의 실시간 데이터 처리를 위해 배치 전송, 파티션, 분산 기능을 구현했다.
* 중앙 시스템의 역할을 하는 중요한 서비스에서 서버 장애가 발생하더라도 서비스에 영향이 없도록 데이터의 안정적인 저장을 위해 리플리케이션 기능을 구현했다.
* 분산된 서버에서 자동으로 파티션의 리더를 선출하는 기능을 구현했다.
* 파이프라인을 표준화하고 통합하길 원했고, 처리량에 중점을 두고 카프카를 설계했다.
* 카프카에는 높은 처리량과 빠른 메시지 전송, 운영 효율화 등을 위해 분산 시스템, 페이지 캐시, 배치 전송 처리 등의 기능이 구현되었다.

#### 분산 시스템
* 분산 시스템은 네트워크로 이루어진 컴퓨터들의 그룹으로서 시스템 전체가 공통의 목표를 가지고 있다.
* 같은 역할을 하는 여러 대의 서버로 이뤄진 서버 그룹을 분산 시스템이라고 한다.
* 장점
    * 단일 시스템보다 더 높은 성능을 얻을 수 있다.
    * 분산 시스템 중 하나의 서버 또는 노드 등이 장애가 발생하면 다른 서버 또는 노드가 대신 처리한다.
    * 시스템 확장이 용이하다.
* 동일한 역할을 하는 서버를 추가해 부하를 분산할 수 있는 것이 분산 시스템의 장점이다.
* 불필요하게 서버만 계속 추가하면 불필요한 비용이 증가하는 단점도 있다.
* 무조건 서버를 늘려 부하를 분산하기보다는 장애 상황과 서버의 리소스 사용량 등을 고려해 적절한 수로 유지하는 것이 좋다.
* 카프카도 분산 시스템이기 때문에 유동적으로 서버를 늘릴 수 있다.

#### 페이지 캐시
* 카프카는 처리량을 높이기 위한 기능을 몇 가지 추가했고 그 기능 중 하나가 페이지 캐시를 이용하는 것이다.
* OS는 물리적 메모리에 애플리케이션이 사용하는 부분을 할당하고 남은 잔여 메모리 일부를 페이지 캐시로 유지해 OS의 전체적인 성능 향상을 높이게 된다.
* 잔여 메모리를 이용해 디스크에 읽고 쓰기를 하지 않고 페이지 캐시를 통해 읽고 쓰는 방식을 사용하면 처리 속도가 매우 빠르기 때문에 전체적인 성능을 향상시킬 수 있다.
* 카프카는 이러한 특징을 이용해 빠른 엑세스를 하기 위해 OS의 페이지 캐시를 이용하도록 디자인되었다.
* 이런 장점 덕분에 카프카를 구성할 때는 디스크 중에서 가격이 가장 저렴한 SATA 디스크를 사용해도 무방하다.

#### JVM 힙 사이즈
* 카프카는 자바 기반의 JVM을 사용하는 애플리케이션으로서 자바 기반 애플리케이션들은 시작할 때 메모리가 할당되는 영역인 힙(heap)이 만들어진다.
* 카프카는 기본값으로 1GB의 힙 메모리를 사용하도록 설정되어 있고, 설정 파일에서 이 값을 변경할 수 있다.
* 카프카는 초당 메시지 단위, 메가비트 단위를 처리함에 있어 5GB의 힙 메모리면 충분하고, 남아 있는 메모리는 페이지 캐시로 사용하기를 권장한다.
* 페이지 캐시를 서로 공유해야 하기 때문에 하나의 시스템에 카프카를 다른 애플리케이션과 함께 실행하는 것은 권장하지 않는다.

#### 배치 전송 처리
* 서버와 클라이언트 사이 또는 서버 내부적으로 데이터를 주고받는 과정에서는 I/O가 발생하기 마련이다.
* 작은 I/O가 빈번하게 일어나게 되면 이 또한 속도를 저하시키는 원인이 될 수 있다.
* 카프카에서는 작은 I/O들을 묶어서 처리할 수 있도록 배치 작업으로 처리한다.
* 서버와 클라이언트 통신 사이에서 매우 작은 메시지를 한 번에 하나씩 보내게 되면 그만큼 네트워크 왕복의 오버헤드가 발생하게 된다.
* 메시지를 보내는 시간을 1초라고 가정한다면, 작은 메시지 4개를 보내는 데 총 4초가 소요 된다.
* 작은 메시지들을 묶어서 한 번에 보내게 되면 네트워크 왕복 오버헤드 등을 줄이게 되어 메시지 4개를 보내는 데 1초의 시간이 소요된다.
* 이러한 배치 작업은 속도 향상에 매우 큰 도움을 준다.

#### 카프카 데이터 모델
* 카프카가 고성능, 고가용성 메시징 애플리케이션으로 발전한 데는 토픽과 파티션이라는 데이터 모델의 역할이 컸다.
* 토픽은 메시지를 받을 수 있도록 논리적으로 묶은 개념이고, 파티션은 토픽을 구성하는 데이터 저장소로서 수평 확장이 가능한 단위이다.

#### 토픽
* 카프카 클러스터는 토픽(topic)이라 불리는 곳에 데이터를 저장한다.
* 메일 시스템과 비교하면, 토픽은 메일주소(토픽)라고 생각하면 쉽다.
* 카프카에 뉴스 토픽, 동영상 토픽, 이미지 토픽이 있다면, 뉴스와 관련된 프로듀서들은 카프카의 뉴스 토픽으로만 메시지를 보내고, 동영상과 관련된 프로듀서들은 카프카의 동영상 토픽으로만 메시지를 보내게 된다.
* 뉴스 담당자가 뉴스에 관한 내용만 가져와서 보고 싶다면, 카프카의 뉴스 토픽에 컨슈머를 연결해 뉴스 토픽의 메시지만 가져올 수 있다.
* 동영상에 관심 있는 담당자라면, 카프카의 동영상 토픽에 컨슈머를 연결하여 동영상 토픽의 메시지만 가져올 수 있다.

#### 파티션
* 카프카에서 파티션이란 토픽을 분할한 것이다. 하나의 토픽을 파티셔닝 한 것이다.
* 하나의 프로듀서가 한개의 파티션으로 4개의 메시지 전송
    * 메시지를 하나 보내는 시간은 1초라고 가정
    * 프로듀서는 뉴스 토픽으로 메시지를 보내기 위해 A메시지 전송이 완료된 후 B메시지를 보내고, 마찬가지로 B메시지 전송이 완료된 후 C메시지, D메시지 순으로 보낸다.
    * 모든 메시지를 전송하는 데 4초가 소요되었다.
* 4개의 프로듀서가 4개의 파티션으로 4개의 메시지 전송
    * 메시지를 하나 보내는 시간은 1초라고 가정
    * 프로듀서만 4개로 변경하고 파티셔은 1개로 유지한다면 일반적인 분산 시스템의 경우라면 4배의 성능을 보장할 가능성이 높지만, 메시징 큐 시스템의 경우 한 가지 제약조건이 있다. = 메시지의 순서가 보장되어야 한다.
    * 그렇기 때문에 이전 메시지 처리가 완료된 후 다음 메시지를 처리하게 된다.
* 결국 카프카에서 효율적인 메시지 전송과 속도를 높이려면 토픽의 파티션 수를 늘려 줘야 한다.
* 토픽에 대한 파티션 수를 1개에서 4개로 변경하고, 파티션 수와 동일하게 프로듀서 수도 4개로 늘렸다.
* 각 프로듀서는 하나의 메시지를 뉴스 토픽의 파티션으로 보내게 된다.
* 병렬 처리 방식으로 동시에 뉴스 토픽으로 메시지를 보낼 수 있게 되어 4개의 메시지를 보내는 데 모두 1초가 소요되었다.
* 빠른 전송을 위해서는 토픽의 파티션을 늘려줘야 하며, 그 수만큼 프로듀서 수도 늘려야 제대로 된 효과를 볼 수 있다.

#### 무조건 파티션 수를 늘려야 하나
* 토픽의 파티션 수가 증가함에 따라 빠른 전송이 가능하다.
* 파티션 수가 늘어나면 오히려 카프카에 좋지 않은 영향을 미칠 수도 있다.

##### 파일 핸들러의 낭비
* 각 파티션은 브로커의 디렉토리와 매핑되고, 저장되는 데이터마다 2개의 파일(인덱스와 실제 데이터)이 있다.
* 카프카에서는 모든 디렉토리의 파일들에 대해 파일 핸들을 열게 된다.
* 파티션의 수가 많을수록 파일 핸들 수 역시 많아지게 되어 리소스를 낭비하게 된다.

##### 장애 복구 시간 증가
* 카프카는 높은 가용성을 위해 리플리케이션을 지원한다.
* 브로커에는 토픽이 있고, 토픽은 여러 개의 파티션으로 나뉘어 있으므로, 브로커에는 여러 개의 파티션이 존재한다.
* 각 파티션마다 리플리케이션이 동작하게 되며, 하나는 파티션의 리더이고, 나머지는 파티션의 팔로워가 된다.
* 만약 브로커가 다운되면 해당 브로커에 리더가 있는 파티션은 일시적으로 사용할 수 없게 되므로, 카프카는 리더를 팔로워 중 하나로 이동시켜 클라이언트 요청을 처리할 수 있게 한다.
* 이와 같은 장애 처리는 컨트롤러로 지정된 브로커가 수행한다.
* 컨트롤러는 카프카 클러스터 내 하나만 존재하고, 만약 컨트롤러 역할을 수행하는 브로커가 다운되면 살아 있는 브로커 중 하나가 자동으로 컨트롤러 역할을 대신 수행한다.
* 최악의 상황으로 다운된 브로커가 컨트롤러인 경우라면, 컨트롤러가 살아있는 브로커에게 완전히 넘어가기 전까지 새로운 리더를 선출할 수 없다.
* 컨트롤러의 페일오버(failover)는 자동으로 동작하지만 새 컨트롤러가 초기화하는 동안 주키퍼에서 모든 파티션의 데이터를 읽어야 한다.
* 카프카 수를 무작정 늘리다 보면 미처 생각하지 못한 문제들이 발생할 수 있다.
* 무작정 파티션 수를 늘리기보다는 적절한 값으로 설정해 운영하는 편이 좋다.

#### 내 토픽의 적절한 파티션 수는
* 먼저 토픽의 파티션 수를 정할 때 원하는 목표 처리량의 기준을 잡아야 한다.
* 프로듀서 입장에서 4개의 프로듀서를 통해 각각 초당 10개의 메시지를 카프카의 토픽으로 보낸다고 하면, 카프카의 토픽에서 초당 40개의 메시지를 받아줘야 한다.
* 해당 토픽에서 파티션을 1로 했을 때 초당 10개의 메시지만 받아준다면 파티션을 4개로 늘려서 목표 처리량을 처리 할 수 있도록 변경한다.
* 토픽의 파티션 수를 4개로 정해 프로듀서의 목표치는 달성했다.
* 카프카에서는 컨슈머도 있기 때문에 컨슈머의 입장도 고려해야 한다.
* 컨슈머 입장에서 8개의 컨슈머를 통해 각각 초당 5개의 메시지를 카프카의 토픽에서 가져올 수 있다고 한다면, 해당 토픽이 파티션 수는 컨슈머 수와 동일하게 8개로 맞추어 컨슈머마다 각각의 파티션에 접근할 수 있게 해야 한다.
* 예상 목표치를 가지고 파티션 수를 할당하는 것이 가장 이상적인 방법이다.
* 카프카에서 파티션의 증가는 필요한 경우 아무때나 변경이 가능하지만, 반대로 파티션의 수를 줄이는 방법은 제공하지 않는다.
* 너무 과도하게 파티션 수를 늘려놓고 난 후에 파티션 수를 줄이고 싶은 상황이 생기면, 토픽을 삭제하는 방법 말고는 다른 해결책이 없다.
* 적절한 파티션 수를 측정하기 어려운 경우에는 일단 적은 수의 파티션으로 운영해보고, 프로듀서 또는 컨슈머에서 병목현상이 발생하게 될 때 조금씩 파티션 수와 프로듀서 또는 컨슈머를 늘려가는 방법으로 적정 파티션 수를 할당할 수 있다.
* 카프카에서는 브로커당 약 2000개 정도의 최대 파티션 수를 권장하고 있기 때문에 과도한 파티션 수를 적용하기 보다는 목표 처리량에 맞게 적절한 파티션 수로 유지, 운영하기를 추천한다.

#### 오프셋과 메시지 순서
* 카프카에서는 각 파티션마다 메시지가 저장되는 위치를 오프셋(offset)이라고 부른다.
* 오프셋은 파티션 내에서 유일하게 순차적으로 증가하는 숫자(64비트) 형태로 되어 있다.
* 쓰기(Write)의 의미는 프로듀서가 메시지를 보내면 메시지가 각 파티션 별로 분산되어 데이터를 저장하는 상태를 나타낸다.
* 각각의 파티션에는 프로듀서가 전송한 메시지들이 저장되어 있으며, 저장된 위치를 유니크하고 순차적인 숫자 형태인 0, 1, 2 같은 형태로 나타내고 있다.
* 이러한 숫자는 파티션마다 유니크한 값을 가지며 카프카에서 이를 오프셋(offset)이라고 한다.
* 오프셋은 하나의 파티션 내에서만 유일한 숫자이다.
* 카프카에서는 이 오프셋을 이용해 메시지의 순서를 보장한다.
* 만약 하나의 토픽을 3개의 파티션으로 나누었다고 가정하면
    * 토픽 기준으로 오프셋이 0인 것을 찾아보면 전부 3개가 존재한다.
    * 하지만 0번 파티션 기준으로 보면 오프셋 0은 유일한 값이다.
    * 파티션1과 2에서도 동일하다.
    * 카프카에서는 이 오프셋을 이용해 메시지의 순서를 보장한다.
* 만약 컨슈머가 파티션 0에서 데이터를 가져간다고 가정하면, 오프셋 0, 1, 2, 3, 4, 5 순서대로만 가져갈 수 있다.
* 절대로 오프셋 순서가 바뀐 상태로는 가져갈 수 없다.

#### 카프카의 고가용성과 리플리케이션
* 카프카는 분산 애플리케이션으로 서버의 물리적 장애가 발생하는 경우에도 높은 가용성을 보장한다.
* 이를 위해 카프카는 리플리케이션(Replication(복제)) 기능을 제공한다.
* 카프카의 리플리케이션은 토픽 자체를 리플리케이션하는 것이 아니라, 토픽을 이루는 각각의 파티션을 리플리케이션하는 것이다.

#### 리플리케이션 팩터와 리더, 팔로워의 역할
* 카프카에서는 리플리케이션 팩터(Replication Factor)라는 것이 있다.
* 카프카의 기본값 설정은 1로 설정되어 있으며, 이를 변경하고 싶으면 카프카 설정 파일에서 수정할 수 있다.
* 각 토픽별로 다른 리플리케이션 팩터 값을 설정할 수 있다.
* 운영 중에도 토픽의 리플리케이션 팩터 값은 변경할 수 있다.
* 만약 설정 파일에서 해당 항목이 없다면 기본값이 적용되어 있는 것이므로, 변경하려면 설정 파일의 맨 아래에 코드 한 줄을 추가하면 된다.
* 클러스터 내 모든 브로커에 동일하게 설정해야 하며, config 내용을 변경한 후 브로커 1대씩 재시작을 하면 변경 내용이 적용된다.

#### 예시
* 카프카 클러스터를 3대의 브로커로 구성하고 프로듀서가 peter라는 토픽으로 메시지를 보내는 상황, 리플리케이션의 동작의 이해를 돕기 위해 파티션이 아닌 토픽이 리플리케이션되는 것으로 설명
* peter 토픽은 리플리케이션이 구성되지 않아 브로커 1에만 위치하고 있으며, 프로듀서가 peter 토픽으로 메시지를 보내고 카프카는 peter 토픽으로 오는 프로듀서의 요청을 처리하고 메시지를 저장하는 상태이다.
* 안정적으로 잘 처리하던 중 브로커 3에서 서버의 물리적 장애가 발생해 브로커 3이 갑자기 다운되었다.
* 브로커 3이 다운되었지만, 프로듀서가 메시지를 보내는 peter 토픽은 브로커 1에 있다.
* 브로커 1과 브로커 3은 동일한 카프카 클러스터이지만, 브로커 3이 다운되었다고 해서 브로커 1에 있는 peter 토픽에는 영향을 주지 않는다.
* 즉 peter 토픽은 브로커 3과 관계없이 살아 있는 상태를 유지하고 있어 프로듀서의 요청을 모두 문제 없이 처리할 수 있다.
* 이번에는 브로커 1이 다운된다면?
* peter 토픽이 있는 브로커 1이 다운되었다.
* 브로커 1이 다운되었기 때문에 브로커 1에 위치한 peter 토픽도 다운된 상태이다.
* 다시 말해 peter 토픽이 다운되면서 프로듀서가 peter 토픽으로 보내는 메시지 요청을 처리할 수 없을 뿐만 아니라 프로듀서의 요청에 대한 응답도 줄 수 없게 되었다.
* 만약 peter 토픽이 기업에서 사용하는 매우 중요한 토픽이라고 하면, 브로커 1 장비의 다운으로 인해 매우 레벨이 높은 장애 상황이 발생하게 된다.

#### 리플리케이션 동작
* peter 토픽에 대해 리플리케이션을 구성했고, peter 토픽은 브로커 1과 브로커 2에 위치한다.
* 이렇게 동일하게 리플리케이션된 토픽을 서로 구분해야 한다.
* 리플리케이션으로 구성된 대부분의 시스템들은 원본과 그것을 리플리케이션한 복제본을 구분하기 위해 각기 다른 용어로 부른다.
* 주키퍼에서는 리더(Leader)와 팔로워(Follower)라고 부르며, 카프카에서는 주키퍼와 동일하게 리더(원본)과 팔로워(복제본)라고 부른다.
* 리더와 팔로워는 각자 역할이 나뉘어 있는데 가장 중요한 핵심은 모든 읽기와 쓰기가 리더를 통해서만 일어난다는 점이다.
* 즉 팔로워는 리더의 데이터를 그대로 리플리케이션만 하고 읽기와 쓰기에는 관여하지 않는다.
* 리더와 팔로워는 저장된 데이터의 순서도 일치하고 동일한 오프셋과 메시지들을 갖게 된다.

* 브로커 1의 peter 토픽은 리더이고, 브로커 2의 peter 토픽은 팔로워이다.
* 프로듀서는 peter 토픽으로 요청을 보내게 되고, 브로커 1의 peter 토픽이 해당 요청에 대하 응답을 하고 있다.
* 브로커 1이 급작스럽게 다운되는 일이 발생했고, 브로커 1의 peter 토픽의 리더도 같이 다운되었다.
* 하지만 브로커 2에 남아있는 peter 토픽의 팔로워가 새로운 리더가 되어 프로듀서의 요청에 응답하게 된다.
* 프로듀서 입장에서는 브로커 1 또는 브로커 2가 다운되는 것은 중요하지 않다.
* 다만 프로듀서가 메시지를 끊김없이 보낼 수 있기만 하면 된다.
* 결국 카프카의 리플리케이션 기능을 이용해 리플리케이션된 토픽의 서버가 다운되는 상황이 발생하더라도 리더 변경을 별다른 문제 없이 프로듀서의 요청들을 처리할 수 있게 된다.
* 리플리케이션 기능은 필요한 기능이며 유용한 기능임에 틀림없다.
* 단점
    * peter 토픽의 사이즈가 100GB라고 한다면, 브로커 1에도 100GB의 디스크를 사용하고 브로커 2에도 100GB의 디스크를 사용하게 된다.
    * 만약 리플리케이션 옵션인 복제 설정을 3으로 했다면, 총 300GB로 원래 토픽 사이즈의 3배 크기 저장소가 필요하게 된다.
    * 브로커의 리소스 사용량 증가
    * 브로커에서는 완벽한 리플리케이션을 보장하기 위해 우리가 알아차리지 못하는 사이에 비활성화된 토픽이 리플리케이션을 잘하고 있는지 비활성화된 토픽의 상태를 체크하는 등의 작업이 이뤄지고 있다.
    * 데이터를 동일하게 보정하는 처리 비용이 크지는 않지만 브로커의 일부 리소스 사용량을 증가시키게 된다.
* 모든 토픽에 리플리케이션 팩터 3을 적용하여 운영하기 보다는, 해당 토픽에 저장되는 데이터의 중요도에 따라 리플리케이션 팩터를 2 또는 3으로 설정해 운영하는 것이 좋 더 효율적이다.

#### 리더와 팔로워의 관리
* 분산 애플리케이션은 각자의 방식으로 리플리케이션 작업을 처리한다.
* 카프카에서는 리더와 팔로워라 불리우는 구성으로 리더와 팔로워가 각자의 역할을 맡아 리플리케이션 작업을 처리한다.
* 리더는 모든 데이터의 일기 쓰기에 대한 요청에 응답하면서 데이터를 저장해나간다.
* 팔로워는 리더를 주기적으로 보면서 자신에게 없는 데이터를 리더로부터 주기적으로 가져오는 방법으로 리플리케이션을 유지한다.
* 리더와 팔로워 모두 주어진 역할에 맞게 잘 동작하고 있다면 전혀 문제가 없지만 팔로워에 문제가 있어 리더로부터 데이터를 가져오지 못하면서 정합성이 맞지 않게 된다면?
* 결국 리더가 다운되는 경우 팔로워가 새로운 리더로 승격되어야 하는데, 데이터가 일치하지 않으므로 큰 문제가 발생할 수 있다.
* 카프카에서는 이러한 현상을 방지하고자 ISR(In Sync Replica)이라는 개념을 도입했다.

#### ISR(In Sync Replica)
* 현재 리플리케이션되고 있는 리플리케이션 그룹이다.
* ISR에는 중요한 규칙이 하나 있다. ISR에 속해 있는 구성원만이 리더의 자격을 가질 수 있다.
* 예를 들어 peter 토픽이 리플리케이션 팩터 2로 구성되어 리더는 1번 브로커, 팔로워는 2번 브로커에 위치하고 있다면, ISR 구성원은 1, 2이다.
* 급작스러운 이유로 브로커 1이 다운되면 ISR의 구성원인 2번 브로커에 있는 팔로워가 새로운 리더로 승격할 수 있다.
* 카프카에서는 이렇게 리더가 자신의 역할을 하지 못하게 되는 경우 팔로워가 그 역할을 대신해야 하기 때문에 리더와의 데이터 동기화 작업을 매우 중요하게 처리하고 있으며 이것을 유지하는 것이 바로 ISR이다.
* 즉 ISR이라는 그룹을 만들어 리플리케이션의 신뢰성을 높이고 있는 것이다.
* 예제 토픽은 리더 하나와 팔로워 둘로 구성된 리플리케이션 팩터 3으로 구성되었고, 리더와 팔로워 모두 ISR의 구성원이다.
* 번호 순서대로 구분 동작 설명
1. 프로듀서는 A메시지를 토픽의 리더에게 보낸다.
2. 프로듀서가 보내는 A메시지는 토픽의 리더만이 읽고 쓰기를 할 수 있기 때문에 프로듀서의 요청을 받고 저장한다. 팔로워들은 매우 짧은 주기로 리더에게 새로운 메시지가 저장된 것이 없는지 확인하는데, 팔로워 1은 잘 동작하지만, 팔로워 2는 잘 동작하지 않는다. 리더는 팔로워들이 주기적으로 데이터를 확인을 하고 있는지 확인을 하여 만약 설정된 일정 주기만큼 확인 요청이 오지 않는다면, 리더는 해당 팔로워의 이상을 감지하고, 해당 팔로워는 더 이상 리더의 역할을 대신할 수 없다고 판단해 ISR 그룹에서 해당 팔로워를 추방시키게 된다. ISR에서 추방당한 팔로워는 추방과 동시에 ISR 그룹에서의 리더 자격도 박탈당하게 된다.
3. 리더가 팔로워 2를 ISR 그룹에서 추방시키자 ISR 그룹 구성원은 3에서 2로 축소되었다. 팔로워 1은 리더에게 새로운 메시지가 왔음을 확인하고 컨슈머들이 메시지를 가져가는 방법(put)처럼 리더의 메시지를 가져와 저장한다.
* ISR의 최종 구성은 리더와 팔로워 1이며 만약 이러한 상황에서 리더에게 문제가 발생하여 다운되는 경우 ISR 구성원인 팔로워 1이 리더로 승격하게 되고, 프로듀서와 컨슈머들이 요청들을 이어서 처리하게 된다.

#### 모든 브로커가 다운된다면
* 카프카 클러스터 내 브로커 1대 정도의 물리적인 장애나 이슈 등이 발생해도 서비스에는 치명적인 영향을 주지 않는다.
* 최악의 시나리오
1. 카프카 클러스터는 3대의 브로커로 구성되어 있다.
2. 토픽은 리플리케이션 팩터 3 옵션으로 생성했다.
3. 프로듀서가 데이터를 보내는 중 브로커가 1대씩 다운됬다.
4. 최종적으로 카프카 클러스터내 모든 브로커가 다운된 상황이 발생했다.
* 최악의 시나리오 단계별 상황
1. 프로듀서가 A 메시지를 전송했고, 리더와 팔로워들은 모두 A 메시지를 저장했다.
2. 프로듀서가 B 메시지를 전송하기 직전에 급작스럽게 팔로워 2가 있는 브로커가 다운되었고, 리더는 팔로워 2를 ISR에서 제외한다. 프로듀서는 B 메시지를 전송하고, 리더와 팔로워 1은 B 메시지를 저장한다.
3. 프로듀서가 C 메시지를 전송하기 직전에 급작스럽게 팔로워 1이 있는 브로커가 다운되었고, 리더는 팔로워 1를 ISR에서 제외한다. 프로듀서는 C 메시지를 전송하고 리더는 C 메시지를 저장한다.
4. 프로듀서가 D 메시지를 전송하기 직전에 급작스럽게 리더가 있는 브로커 역시 다운되면서 클러스터 내 모든 브로커가 다운되었고, 프로듀서는 더 이상 리더가 존재하지 않기 때문에 메시지를 보낼 수 없다.
* 이렇게 카프카 클러스터가 다운되는 최악의 상황이 발생한 경우, 선택할 수 있는 방법은 두 가지가 있다.
1. 마지막 리더가 살아나기를 기다린다.
2. ISR에서 추방되었지만 먼저 살아나면 자동으로 리더가 된다.

##### 1. 마지막 리더가 살아나기를 기다린다.
* 마지막 리더에게는 메시지 A, B, C가 모두 저장되어 현재는 카프카 클러스터가 모두 다운된 상태이지만 나중에 살아난다면 메시지 손실 없이, 프로듀서의 요청들을 처리하면서 서비스를 지속적으로 제공할 수 있다.
* 클러스터 전체가 다운되는 최악의 경우가 발생했음에도 메시지 손실 없이 장애 상황을 넘길 수 있는 가장 좋은 방법처럼 보이지만 필수 조건이 하나 있다.
* 재시작시 마지막 리더가 반드시 재시작되어야 한다.
* 경우에 따라서는 이 필수 조건이 어려운 조건이 아닐 수 있다.
* 하지만 장애 상황이 자신의 의도와 다르게 동작하는 경우도 있다.
* 예를 들어 최악의 시나리오와 같이 카프카 클러스터 전체가 다운되는 장애 상황이 발생했고, 관리자가 긴급 대응해서 팔로워 1, 2가 있는 브로커는 장애 부분을 고치고 빠르게 정상화되었다.
* 하지만 리더가 있는 브로커는 알 수 없는 이유로 되살아나지 않는다. 관리자는 리더가 반드시 정상화되어야 한다는 사실을 알고 있지만 원인을 알 수 없어 장애 시간이 길어지고 있다.
* 이렇게 클러스터의 다른 브로커들은 정상화되었지만 마지막 리더가 살아나지 않는 경우가 있을 수 있고, 결국 마지막 리더가 정상화될 때가지 전체 카프카 클러스터의 장애가 길어지게 된다.

##### 2. ISR에서 추방되었지만 먼저 살아나면 자동으로 리더가 된다.
* IST에서 추방되었지만 먼저 살아나면 자동으로 리더가 되는 경우에는 마지막 리더가 아닌 클러스터 내에서 가장 먼저 살아나는 리더 또는 팔로워가 새로운 리더가 된다.
* 하지만 마지막 리더가 아닌 ISR에서 추방당한 팔로워가 새로운 리더가 되면 메시지 손실이 발생한다.
* 어떻게 메시지 손실이 발생하는가
* 마지막 리더가 아닌 팔로워 1, 2 중에 먼저 정상화된 토픽이 리더가 되면서
1. 카프카 클러스터 전체가 다운되는 현상이 발생했고, 1대씩 다운되다 보니 리더, 팔로워 1, 팔로워 2가 가지고 있는 메시지는 서로 모두 다른 상태이다.
2. 관리자가 빠르게 장애 대응을 한 덕분에 팔로워 2가 있는 브로커가 먼저 정상화되었고, 토픽의 리더가 아무도 없기 때문에 자동으로 팔로워 2가 새로운 리더가 되었다. 새로운 리더가 되면서 프로듀서가 보내는 D 메시지에 대한 요청을 처리하고 D 메시지를 저장하게 된다.
3. 올드(Old) 리더가 있는 브로커와 팔로워 1이 있는 브로커도 뒤늦게 정상화되었으나, 토픽의 리더를 확인해보니 이미 리더가 존재한다. 리더가 이미 있기 때문에 모두 팔로워가 되면서 리더와 동기화 작업을 시작하게 되고, 결국 새로운 리더와 동일한 상태를 유지하게 된다.
* 올드 리더가 가지고 있던 메시지 B, C와 팔로워 1이 가지고 있던 메시지 B는 손실되었다.
* 비록 메시지는 일부 손실되었지만 클러스터 전체가 다운된 상황에서 브로커 하나만이라도 빠르게 정상화되어 서비스 역시 빠르게 정상화 될 수 있었다.
* 두 가지 방안 모두 장단점이 분명 존재하고 어느 방법이 옳다라고 말하기는 어렵다.
* 카프카에서는 0.11.0.0 이하 버전에서는 기본값으로 2번 방안을 선택해 일부 데이터 손실이 발생하더라도 서비스적인 측면에서 빠르게 서비스를 제공할 수 있게 해준다.
* 하지만 0.11.0.0 버전부터는 기본값을 1번 방안으로 선택해 데이터 손실 없이 마지막 리더가 살아나기를 기다린 후 서비스가 되게 대처한다.
* 사용자의 선택에 따라 관련 설정은 카프카의 설정 파일에서 원하는 옵션으로 변경할 수 있다.
* 가용성과 일관성 중 어느 쪽에 더 초점을 두느냐의 차이이다.
* 카프카를 운영하는 환경에 따라 빠른 서비스 제공을 선호하는지, 데이터 무손실을 선호하는지에 따라 다르다.
* 카프카에서는 토픽이 리플리케이션되는 것이 아니라 토픽을 나눈 각각의 파티션이 리플리케이션된다.

| 토픽명            | Peter-Topic01 | Peter-Topic02 |
| ----------------- | ------------- | ------------- |
| 파티션 수         | 2             | 2             |
| 리플리케이션 팩터 | 3             | 2             |
| 카프카 클러스터   | 3             | 3             |

##### Peter-Topic01
* 파티션 수는 2, 리플리케이션 팩터는 3이다.
* 2개의 파티션을 구분하기 위해 파티션 이름은 파티션01, 파티션02가 된다.
* 리플리케이션 팩터가 3이기 때문에 파티션01에는 리더 1개와 팔로워 2개로 구성된다.
* 리더, 팔로워는 ISR로 구성된 상태이다.
* 파티션02도 파티션01과 동일하게 리더, 팔로워 2개로 구성되고 ISR로 구성되었다.

##### Peter-Topic02
* 파티션 수는 2, 리플리케이션 팩터는 2이다.
* 2개의 파티션을 구분하기 위해 파티션 이름은 파티션01, 파티션02가 된다.
* 리플리케이션 팩터가 2이기 때문에 파티션01에는 리더와 팔로워가 각각 1개씩 구성된다.
* 리더, 팔로워는 ISR로 구성된 상태이다.
* 파티션02도 파티션 01과 동일하게 리더, 팔로워 각각 1개씩 구성되고 ISR로 구성되었다.

#### 카프카에서 사용하는 주키퍼 지노드 역할
* 카프카의 지노드는 /peter-kafka를 사용했고, 예제를 위해 임의로 추가한 토픽 이름과 컨슈머 그룹ID는 peter-topic, peter-consumer로 표시했다.
* /peter-kafka/controller
    * 현재 카프카 클러스터의 컨트롤러 정보를 확인할 수 있다.
    * 리더를 선정하는 프로세스는 굉장히 중요하며 브로커의 실패 등으로 인해 리더가 변경되면 모든 파티션에 대해 파티션마다 리더 선출작업이 필요하게 된다.
    * 카프카에서는 클러스터내 브로커 중 하나를 컨트롤러로 선정해 컨트롤러는 브로커 레벨에서 실패를 감지하고 실패한 브로커에 의해 영향받는 모든 파티션의 리더 변경을 책임지고 있다.
    * 컨트롤러를 통해 많은 수의 파티션들에 대해 매우 빠르게 배치 형태로 리더십을 변경할 수 있다.
    * 컨트롤러는 클러스터 내 브로커가 임의로 선정되고 만약 컨트롤러인 브로커가 다운되면, 남아 있는 브로커 중 하나가 새로운 컨트롤러가 된다.
* /peter-kafka/brokers
    * 브로커 관련된 정보들이 저장되며 카프카 설치할 때 브로커 config에서 수정한 broker.id를 확인할 수 있다.
    * 브로커는 시작시 /brokers/ids에 broker.id로 지노드를 작성해 자신을 등록한다.
    * 만약 이미 사용 중인 broker.id를 등록하려고 시도하면 오류가 발생한다.
    * 주키퍼의 임시노드(ephemeral node)를 사용해 등록하고, 만약 브로커가 종료되거나 다운되면 지노드는 사라진다.
    * 추가로 topics라는 지노드의 정보를 확인해 보면 클러스터 내 토픽 정보들도 확인할 수 있다.
    * 토픽의 파티션 수, ISR 구성 정보, 리더 정보 등을 확인할 수 있다.
* /peter-kafka/consumers
    * 컨슈머 관련된 정보들이 저장되며, 컨슈머가 각각의 파티션들에 대해 어디까지 읽었는지를 기록하는 오프셋 정보가 이곳에 저장된다.
    * 오프셋 정보는 지워지면 안되는 정보이기 때문에 오프셋 관련 정보들은 주키퍼의 영구노드(persistent node)로 저장된다.
    * 카프카 0.9 버전 이후부터는 컨슈머 오프셋 저장 주소를 주키퍼 또는 카프카의 토픽(_consumer_offsets)을 선택할 수 있도록 제공하고 있지만, 향후 카프카의 릴리스에서는 주키퍼에 오프셋을 저장하는 방법은 서비스가 종료될 예정이다.
    * 카프카 최신 버전을 사용하고, 새롭게 컨슈머를 사용하면 오프셋 저장방식을 주키퍼가 아닌 카프카의 토픽으로 저장해 사용하기를 권장한다.
* /peter-kafka/config
    * 토픽의 상세 설정 정보를 확인할 수 있다.
    * 토픽 생성 시 기본값으로 생성한 작업 외에 상세 설정 추가를 통해 retention.ms 등을 별도로 설정한 경우 해당 옵션 정보를 확인할 수 있다.

#### 카프카 프로듀서
* 카프카에서는 메시지를 생산(produce)해서 카프카의 토픽으로 메시지를 보내는 역할을 하는 애플리케이션, 서버 등을 모두 프로듀서라고 부른다.
* 프로듀서의 주요 기능은 각각의 메시지를 토픽 파티션에 매핑하고 파티션의 리더에 요청을 보내는 것이다.
* 키 값을 정해 해당 키를 가진 모든 메시지를 동일한 파티션으로 전송할 수 있다.
* 만약 키 값을 입력하지 않으면, 파티션은 라운드 로빈(round-robin) 방식으로 파티션에 균등하게 분배된다.
  
#### 콘솔 프로듀서로 메시지 보내기
* 프로듀서를 이용해 카프카로 메시지를 보내려면 토픽이 있어야 하므로 미리 토픽을 생성해야 한다.
* 카프카의 옵션 중에 auto.create.topics.enable = true로 되어 있는 경우에는 프로듀서가 카프카에 존재하지 않는 토픽으로 메시지를 보내면, 자동으로 토픽이 생성된다.

#### 메시지를 보내고 확인하지 않기
* 프로듀서에서 서버로 메시지를 보내고 난 후에 성공적으로 도착했는지까지 확인하지는 않는다.
* 카프카가 항상 살아있는 상태이고 프로듀서가 자동으로 재전송하기 때문에 대부분의 경우 성공적으로 전송되지만, 일부 메시지는 손실될 수도 있다.
* send() 메소드를 통해 ProducerRecode를 보낸다.
* 메시지는 버퍼에 저장되고 별도의 스레드를 통해 브로커로 전송한다.
* send()는 자바 퓨처(Future) 객체로 RecoreMetadata를 리턴받지만 리턴값을 무시하기 때문에 메시지가 성공적으로 전송되었는지 알 수 없다.
* 이 방식은 메시지 손실 가능성이 있기 때문에 일반적인 서비스 환경에서는 사용하지 않는다.
* 카프카 브로커에게 메시지를 보낸 후의 에러는 무시하지만, 보내기 전에 에러가 발생하면 예외 처리를 할 수 있다.

#### 동기 전송
* 프로듀서는 메시지를 보내고 send()메소드의 Future 객체를 리턴한다.
* get() 메소드를 사용해 Future를 기다린 후 send()가 성공했는지 실패했는지 확인한다.
* 이러한 방법을 통해 메시지마다 브로커에게 전송한 메시지가 성공했는지 실패했는지 확인하여 더욱 신뢰성있는 메시지 전송을 할 수 있다.
* get() 메소드를 이용해 카프카의 응답을 기다린다.
* 메시지가 성공적으로 전송되지 않으면 예외가 발생하고, 에러가 없다면 메시지가 기록된 오프셋을 알 수 있는 RecodeMetadata를 얻게 된다.
* RecodeMetadata를 이용해 파티션과 오프셋 정보를 출력한다.
* 카프카로 메시지를 보내기 전과 보내는 동안 에러가 나는 경우 예외가 발생한다.
* 예외는 크게 두 가지로 구분되는데, 재시도가 가능한 예외와 재시도가 불가능한 예외가 있다.
* 재시도가 가능한 에러는 다시 전송하여 해결할 수 있다.
* 예를 들면 커넥션 에러 등은 재연결되면서 해결되기도 한다.
* 재시도가 불가능한 예외는 메시지가 너무 큰 경우 등이 있다.

#### 비동기 전송
* 프로듀서는 send() 메소드를 콜백과 같이 호출하고 카프카 브로커에서 응답을 받으면 콜백한다.
* 만약 프로듀서가 보낸 모든 메시지에 대해 응답을 기다린다면 응답을 기다리는 시간이 더 많이 소요된다.
* 하지만 비동기적으로 전송한다면 응답을 기다리지 않기 때문에 더욱 빠른 전송이 가능하다.
* 또한 메시지를 보내지 못했을 때 예외를 처리하게 해 에러를 기록하거나 향후 분석을 위해 에러 로그 등에 기록할 수 있다.
* 콜백을 사용하기 위해 org.apache.kafka.clients.producer.Callback를 구현하는 클래스가 필요하다.
* 카프카가 오류를 리턴하면 onCompletion()는 예외를 갖게 된다.
* 프로듀서에서 레코드를 보낼 때 콜백 오브젝트를 같이 보낸다.

#### 프로듀서 주요 옵션
* boostrap.servers
    * 카프카 클러스터는 클러스터 마스터라는 개념이 없기 때문에 클러스터 내 모든 서버가 클라이언트의 요청을 받을 수 있다.
    * 해당 옵션은 카프카 클러스터에 처음 연결을 하기 위한 호스트와 포트 정보로 구성된 리스트 정보를 나타낸다.
    * 정의된 포맷은 호스트 이름:포트, 호스트 이름:포트 이다.
    * peter-kafka001:9092, peter-kafka002:9092
    * 전체 카프카 리스트가 아닌 호스트 하나만 입력해 사용할 수 있지만 이 방법을 추천하지는 않는다.
    * 카프카 클러스터는 살아 있는 상태이지만 해당 호스트가 장애가 발생하는 경우 접속이 불가능하기 때문에, 리스트 전체를 입력하는 것을 권장한다.
    * 만약 주어진 리스트의 서버 중 하나에서 장애가 발생할 경우 클라이언트는 자동으로 다른 서버로 재접속을 시도하기 때문에 사용자 프로그램에서는 문제 없이 사용할 수 있게 된다.
* acks
    * 프로듀서가 카프카 토픽의 리더에게 메시지를 보낸 후 요청을 완료하기 전 ack(승인)의 수이다.
    * 해당 옵션의 수가 작으면 성능이 좋지만, 메시지 손실 가능성이 있고, 반대로 수가 크면 성능이 좋지 않지만 메시지 손실 가능성도 줄어 들거나 없어진다.
    * acks = 0
        * 만약 0으로 설정하는 경우 프로듀서는 서버로부터 어떠한 ack도 기다리지 않는다.
        * 이 경우 서버가 데이터를 받았는지 보장하지 않고, 클라이언트는 전송 실패에 대한 결과를 알지 못하기 때문에 재요청 설정도 적용되지 않는다.
        * 메시지가 손실될 수 있지만, 서버로부터 ack에 대한 응답을 기다리지 않기 때문에 매우 빠르게 메시지를 보낼 수 있어 높은 처리량을 얻을 수 있다.
    * acks = 1
        * 만약 1로 설정하는 경우 리더는 데이터를 기록하지만, 모든 팔로워는 확인하지 않는다.
        * 이 경우 일부 데이터의 손실이 발생할 수도 있다.
    * acks = all 또는 -1
        * 만약 all 또는 -1로 설정하는 경우 리더는 ISR의 팔로워로부터 데이터에 대한 ack를 기다린다.
        * 하나의 팔로워가 있는 한 데이터는 손실되지 않으며, 데이터 무선실에 대해 가장 강력하게 보장한다.
* buffer.memory
    * 프로듀서가 카프카 서버로 데이터를 보내기 위해 잠시 대기(배치 전송이나 딜레이 등)할 수 있는 전체 메모리 바이트(bytes)이다.
* compression.type
    * 프로듀서가 데이터를 압축해서 보낼 수 있는데, 어떤 타입으로 압축할지를 정할 수 있다.
    * 옵션으로 none, gzip, snappy, lz4 같은 다양한 포맷 중 하나를 선택할 수 있다.
* retries
    * 일시적인 오류로 인해 전송이 실패한 데이터를 다시 보내게 된다.
* batch.size
    * 프로듀서는 같은 파티션으로 보내는 여러 데이터를 함께 배치로 보내려고 시도한다.
    * 이러한 동작은 클라이언트와 서버 양쪽에 성능적인 측면에서 도움이 된다.
    * 이 설정으로 배치 크기 바이트(batch size byte) 단위를 조정할 수 있다.
    * 정의된 크기 보다 큰 데이터는 배치를 시도하지 않게 된다.
    * 배치를 보내기 전 클라이언트 장애가 발생하면 배치 내에 있던 메시지는 전달되지 않는다.
    * 만약 고가용성이 필요한 메시지의 경우라면 배치 사이즈를 주지 않는 것도 하나의 방법일 수 있다.
* linger.ms
    * 배치 형태의 메시지를 보내기 전에 추가적인 메시지들을 위해 기다리는 시간을 조정한다.
    * 카프카 프로듀서는 지정된 배치 사이즈에 도달하면 이 옵션과 관계없이 즉시 메시지를 전송하고, 배치사이즈에 도달하지 못한 상황에서 linger.ms 제한 시간에 도달했을 때 메시지들을 전송한다.
    * 0이 기본값(지연 없음)이며, 0보다 큰 값을 설정하면 지연 시간은 조금 발생하지만 처리량은 좋아진다.
* max.request.size
    * 프로듀서가 보낼 수 있는 최대 메시지 바이트 사이즈이다.
    * 기본값은 1MB이다.

#### 메시지 전송 방법
* 프로듀서의 옵션 중 acks 옵션을 어떻게 설정하는지에 따라 카프카로 메시지를 전송할 때 메시지 손실 여부와 메시지 전송 속도 및 처리량 등이 달라지게 된다.
* 각 옵션은 정확하게 이해하고 사용해야 한다.

#### 메시지 손실 가능성이 높지만 빠른 전송이 필요한 경우
* acks = 0
* 메시지를 전송할 때 프로듀서는 카프카 서버에서 응답을 기다리지 않고, 메시지를 보낼 준비가 되는 즉시 다음 요청을 보낸다.
* 카프카로부터 응답을 기다리지 않고 프로듀서만 준비되면 즉시 보내기 때문에 매우 빠르게 메시지를 보낼 수 있다.
* 하지만 이런 방법으로 사용하게 되면, 프로듀서가 카프카로부터 자신이 보낸 메시지에 대해 응답을 기다리지 않기 때문에 메시지가 손실될 수 있다.
* 프로듀서가 AAA라는 메시지를 전송했지만, 어떠한 이유로 인해 AAA메시지가 카프카로 도착하지 않았다.
* 하지만 프로듀서는 카프카의 응답 확인을 하지 않기 때문에 카프카가 메시지를 잘 받았는지 못 받았는지를 전혀 알 수가 없다.
* 단지 프로듀서가 또 다른 메시지를 보낼 준비가 되면 계속해서 카프카로 메시지만 전송한다.
* 일부 메시지 손실을 감안하더라도 매우 빠르게 전송이 필요한 경우에 사용하는 옵션이다.
* 메시지 손실이 발생한다고 해서 프로듀서가 보내는 메시지의 90% 이상 손실된다는 의미는 아니다.
* 일반적인 운영 환경의 경우 메시지 손실 없이 빠르게 보내지만, 브로커가 다운되는 장애 등의 경우에 메시지 손실 가능성이 높은 편이다.

#### 메시지 손실 가능성이 적도 적당한 속도의 전송이 필요한 경우
* acks = 1
* 프로듀서가 카프카로 메시지를 보낸 후 보낸 메시지에 대해 카프카가 잘 받았는지 확인(acks)을 한다.
* 응답 대기 시간 없이 계속 메시지만 보내던 방법과 달리 확인을 기다리는 시간이 추가되어 메시지를 보내는 속도는 약간 떨어지게 된다.
* 메시지 하나를 보내기 위해 보내는 행동 + 응답을 받는 행동을 하여 메시지를 하나 보내는 데 2초가 소요된다. (보내는 시간 1초 일 때)
* 메시지 전송 시간은 다소 느리지만, 보낸 메시지에 대한 응답을 받기 때문에 acks = 0과 비교해 메시지 손실률은 매우 낮다.
* 아주 예외적인 상황으로 acks = 1의 경우에도 메시지 일부가 손실되는 현상이 발생하게 된다.
* 프로듀서가 메시지를 보냈을 때 리더와 팔로워들에게 메시지가 저장되는 과정
1. 프로듀서가 acks = 1옵션으로 peter-topic의 리더에게 메시지를 보낸다.
2. peter-topic의 리더는 메시지를 받은 후 저장한다.
3. peter-topic의 리더는 프로듀서에게 메시지를 받았다고 acks를 보낸다.
4. 팔로워들은 리더를 주기적으로 바라보고 있다.
5. 리더에 새로운 메시지가 있는 것을 확인하고 팔로워들도 저장한다.
* 프로듀서가 메시지를 전송하고, 카프카가 해당 메시지를 저장하는 과정을 보면 일반적인 경우에는 아무런 문제가 없다.
* 하지만 메시지 손실 등의 문제가 발생하는 경우는 바로 리더에 장애가 발생하는 순간이다.
* 그러나 리더에 장애가 발생한다고 해서 100%의 확률로 메시지가 손실되는 것은 아니고 특별한 상황이 발생했을 때만 메시지 일부가 손실된다.
* 메시지가 손실되는 경우
1. 프로듀서가 acks = 1 옵션으로 peter-topic의 리더에게 메시지를 보낸다.
2. peter-topic의 리더는 메시지를 받은 후 저장한다.
3. peter-topic의 리더는 프로듀서에게 메시지를 받았다고 acks를 보낸 후 바로 장애 발생
4. 팔로워들은 리더를 주기적으로 바라봐야 하는데 리더가 없는 상태이다.
5. 리더에 새로운 메시지가 있는지를 모르기 때문에 메시지를 가져올 수 없다.
* 프로듀서가 전송한 메시지는 브로커 2에만 저장되어 있는 상태이고, 팔로워들은 리더가 급작스럽게 다운되면서 해당 메시지를 가지고 있지 않다.
* 카프카에서는 리플리케이션 동작 방식에 따라 리더가 다운되었기 때문에 팔로워 중 하나가 새로운 리더가 되고, 프로듀서의 요청을 처리하게 된다.
* 카프카에서는 리더에 장애가 발생하자마자 팔로워 중 하나가 peter-topic의 새로운 리더가 되어야 한다.
* 팔로워들은 브로커 2로부터 장애 발생 직전의 메시지는 가져 오지 못하였지만 그 상태 그대로 새로운 리더가 되는 것이다.
* 카프카의 이러한 동작은 리플리케이션 방법에 의해 미리 정의된 동작에 따른 것이고, 오류 등은 없었다.
* 프로듀서 입장에서 보면 acks = 1 옵션의 규칙에 따라 메시지를 전송하고 보낸 메시지에 대해 리더로부터 acks를 받았기 때문에 카프카에 잘 저장된 것으로 인지하고, 다음 메시지를 전송할 준비를 한다.
* 프로듀서 역시 오류 등은 없었으며 모두 미리 정의된 프로세스에 따라 처리했다.
* 즉 프로듀서, 리더, 팔로워 어느 누구도 잘못된 동작을 하지 않았지만, 이렇게 프로듀서가 acks = 1로 보낸 메시지는 손실되었다.
* 이것이 바로 프로듀서 acks = 1로 설정했을 때, 메시지가 손실하는 아주 예외적인 상황이다.
* 다른 프로듀서의 acks 옵션 기본값을 1로 하고 있고, 다른 프로듀서 애플리케이션들도 acks 옵션의 기본값이 1인 경우가 많이 있다.
* 특별한 경우가 아니라면 속도와 안전성을 확보할 수 있는 acks = 1로 사용하는 방법을 추천한다.

#### 전송 속도는 느리지만 메시지 손실이 없어야 하는 경우
* 카프카를 사용하는 사용자의 입장에서 절대 손실되지 않는 메시지를 보내는 경우도 있다.
* 그래서 카프카에서는 acks = 1 보다 더 강력한 보장을 할 수 잇는 acks = all 이라는 옵션을 제공한다.
* acks = all의 동작 방법은 프로듀서가 메시지를 전송하고 난 후 리더가 메시지를 받았는지 확인하고 추가로 팔로워까지 메시지를 받았는지 확인하는 것이다.
* 속도적인 측면으로 볼 때, acks 옵션 중에 가장 느리지만 메시지 손실을 허용하지 않을 경우 사용하는 옵션이다.
* acks = all을 완벽하게 사용하고자 한다면, 프로듀서의 설정 뿐만 아니라 브로커의 설정도 같이 조정해야 한다.
* 브로커의 설정에 따라 응답 확인을 기다리는 수가 달라지게 된다.

#### 프로듀서의 acks = all과 브로커의 min.insync.replicas = 1
* 메시지 손실을 허용하지 않도록 프로듀서의 acks 설정은 all로 지정을 한다.
* 브로커의 설정은 환경 설정 파일인 server.properties에서 설정을 변경할 수 있다.
* 최소 리플리케이션 팩터를 지정하는 옵션은 min.insync.replicas이다.
* 예제 토픽은 peter-topic를 이용하며 리플리케이션 팩터 옵션은 3으로 구성된 토픽이다.
* 먼저 첫 번째 브로커 환경설정에서 min.insync.replicas의 옵션이 1로 되어 있다고 가정
1. 프로듀서가 acks = all 옵션으로 peter-topic의 리더에게 메시지를 보낸다.
2. peter-topic의 리더는 메시지를 받은 후 저장한다.
3. peter-topic의 리더는 min.insync.replicas가 1로 설정되어 있고 최소 하나의 리플리케이션 조건을 갖췃기 때문에 프로듀서에게 메시지를 받았다고 acks를 보낸다.
* 손실 없는 메시지 전송을 위해 프로듀서가 acks = all 옵션으로 메시지를 전송했지만, acks = 1과 동일하게 동작하게 된다.
* 이렇게 동작하는 이유는 브로커 환경설정에 min.insync.replicas에 정의된 값이 1이기 때문이다.
* 카프카에서는 프로듀서만 acks = all로 메시지를 보낸다고 해서 손실 없는 메시지를 보장해주는 것이 아니기 때문에 옵션을 잘 이해하고 설정해야 한다.

#### 프로듀서의 acks = all과 브로커의 min.insync.replicas = 2
* 두 번째 브로커 환경설정에서 min.insync.replicas의 옵션이 2로 되어 있다고 가정
1. 프로듀서가 acks = all 옵션으로 peter-topic의 리더에게 메시지를 보낸다.
2. peter-topic의 리더는 메시지를 받을 후 저장한다. 브로커 1에 있는 팔로워는 변경된 사항이나 새로 받은 메시지가 없는지를 리더로부터 주기적으로 확인하면서, 새로운 메시지가 전송된 것을 확인하면 자신도 리더로부터 메시지를 가져와 저장한다.
3. peter-topic의 리더는 min.insync.replicas가 2로 설정되어 있기 때문에 acks를 보내기 전 최소 2개의 리플리케이션을 유지하는지 확인한다.
4. peter-topic의 리더는 프로듀서가 전송한 메시지에 대해 acks를 프로듀서에게 보낸다.
* 손실 없는 메시지 전송을 위해 프로듀서가 acks = all 옵션으로 메시지를 전송했고, 프로듀서는 acks를 받았다.
* 만약 리더가 acks를 보내자마자 아주 예외적인 경우로 리더 선출 작업이 발생해도 그 메시지를 가지고 있는 팔로워가 있기 때문에 메시지 손실은 발생하지 않는다.
* 아파치 카프카 문서에서는 손실 없는 메시지 전송을 위한 조건으로 프로듀서는 acks = all, 브로커의 min.insync.replicas의 옵션은 2, 토픽의 리플리케이션 팩터는 3으로 권장하고 있다.
* 브로커 1이 다운되는 상황이 발생하더라도 남아 있는 팔로워가 또 있기 때문에 min.insync.replicas = 2를 유지할 수 있게 된다.
* 1대 정도의 서버 장애가 발생하더라도 손실 없는 메시지 전송을 유지할 수 있다.
* 손실 없는 메시지 전송을 원한다면, acks = all과 min.insync.replicas = 2와 리플리케이션 팩터=3 조건으로 사용하면 된다.

#### 프로듀서의 acks = all과 브로커의 min.insync.replicas = 3
* 손실 없는 메시지 전송을 위해 min.insync.replicas = 3으로 설정해야 하는 것이 아닌가라고 생각할 수 있다.
* 왜 min.insync.replicas = 2로 설정해야 하는 이유
* 브로커 환경설정에서 min.insync.replicas의 옵션이 3으로 되어있다고 가정
1. 프로듀서가 acks = all 옵션으로 peter-topic의 리더에게 메시지를 보낸다.
2. peter-topic의 리더는 메시지를 받은 후 저장한다. 브로커 1에 있는 팔로워는 변경된 사항이나 새로 받은 메시지가 없는지를 리더로부터 주기적으로 확인하면서, 새로운 메시지가 전송된 것을 확인하면 자신도 리더로부터 메시지를 가져와 저장한다.
3. peter-topic의 리더는 min.insync.replicas가 3으로 설정되어 있기 때문에 acks를 보내기 전 최소 3개의 복제를 유지하는지 확인한다.
4. peter-topic의 리더는 프로듀서가 전송한 메시지에 대해 acks를 프로듀서에게 보낸다.
* 동작 방법만 봤을 땐 min.insync.replicas = 3이 가장 강력한 방법일것 같다.
* 프로듀서 옵션에 acks = all이라고 정의했고, 브로커에서는 min.insync.replicas = 3으로 설정했다.
* 이렇게 설정한 경우 프로듀서가 토픽의 리더에게 메시지를 전송하게 되면, 리더 + 팔로워 + 팔로워 이렇게 3곳에서 모두 메시지를 받아야만 리더는 프로듀서에게 메시지를 잘 받았다는 acks(확인)를 보낼 수 있다.
* 하지만 여기서 브로커 3번을 강제로 종료하게 되면서, 팔로워 하나가 다운되었고 ISR에는 리더와 팔로워 하나만 남아 있다.
* 결국 옵션으로 설정한 조건을 충족시킬 수 없는 상황이 발생했기 때문에 로그에 에러가 발생하는 것이다.
* 카프카는 브로커 하나가 다운되더라도 크리티컬한 장애 상황없이 서비스를 잘 처리할 수 있도록 구성되어 있다.
* 만약 acks = all + min.insync.replicas = 3으로 설정하게 되면 브로커 하나만 다운되더라도 카프카로 메시지를 보낼 수 없는 클러스터 전체 장애와 비슷한 상황이 발생하게 된다.
* 이러한 이유로 카프카에서는 손실 없는 메시지 전송을 위해 프로듀서의 acks = all로 사용하는 경우 브로커의 min.insync.replicas = 2로 설정하고, 토픽의 리플리케이션 팩터는 3으로 설정하기를 권장하고 있다.
* 만약 권장하는 옵션대로 설정했다면, 테스트 시나리오와 동일한 현상이 발생하더라도 서비스 장애 없이 안정적으로 프로듀서의 요청들을 처리할 수 있다.
* 물론 아주 예외적인 상황으로 브로커가 2대까지 다운되는 경우에는 프로듀서들의 요청을 처리할 수 없는 상황이 발생한다.

#### 컨슈머
* 프로듀서가 메시지를 생산해서 카프카의 토픽으로 메시지를 보내면 그 토픽의 메시지를 가져와서 소비(consume)하는 역할을 하는 애플리케이션, 서버 등을 지칭하여 컨슈머라고 한다.
* 컨슈머의 주요 기능은 특정 파티션을 관리하고 있는 파티션 리더에게 메시지 가져오기 요청을 하는 것이다.
* 각 요청은 로그의 오프셋을 명시하고 그 위치로부터 로그 메시지를 수신한다.
* 그래서 컨슈머는 가져올 메시지의 위치를 조정할 수 있고, 필요하다면 이미 가져온 데이터도 다시 가져올 수 있다.
* 이미 가져온 메시지를 다시 가져올 수 있는 기능은 RabbitMQ와 같은 일반적인 메시지큐 솔루션에서는 제공하지 않는 기능이다.
* 하지만 최근에는 메시지큐 솔루션 사용자들에게 이러한 기능이 오히려 필수 기능으로 자리 잡고 있다.

#### 컨슈머 주요 옵션
* 카프카에서 컨슈머라고 불리우는 컨슈머는 두 가지 종류가 있는데 하나는 올드 컨슈머(Old Consumer) 라고 부르고, 다른 하나는 뉴 컨슈머(New Consumer)라고 한다.
* 두 컨슈머의 가장 큰 차이는 주키퍼의 사용 유무이다.
* 구 버전의 카프카에서는 컨슈머의 오프셋을 주키퍼의 지노드에 저장하는 방식을 지원하다가 카프카 버전 0.9 부터 컨슈머의 오프셋 저장을 주키퍼가 아닌 카프카의 토픽에 저장하는 방식으로 변경했다.
* 아직까지는 컨슈머의 오프셋 저장 방법이 주키퍼의 지노드 또는 카프카의 토픽을 이용한 방식 모두를 지원하고 있지만, 향후 릴리스 되는 카프카 버전에서는 주키퍼의 지노드에 저장하는 방식은 사라질 예정이다.
* 최신의 컨슈머 클라이언트들도 대부분 뉴 컨슈머로 구현되어 있기 때문에 뉴 컨슈머 기준 예시
* bootstrap.servers
    * 카프카 클러스터에 처음 연결을 하기 위한 호스트와 포트 정보로 구성된 리스트 정보를 나타낸다.
    * 정의된 포맷은 호스트명:포트, 호스트명:포트 이다.
    * 전체 카프카 리스트가 아닌 호스트 하나만 입력해 사용할 수도 있지만 이 방식은 추천하지 않는다.
    * 카프카 클러스터는 살아 있는 상태이지만 해당 호스트만 장애가 발생하는 경우에는 접속이 불가하기 때문에, 리스트 전체를 입력하는 방식을 권장한다.
* fetch.min.bytes
    * 한번에 가져올 수 있는 최소 데이터 사이즈이다.
    * 만약 지정한 사이즈보다 작은 경우, 요청에 대해 응답하지 않고 데이터가 누적될 때까지 기다린다.
* group.id
    * 컨슈머가 속한 컨슈머 그룹을 식별하는 식별자이다.
    * 그룹 아이디는 매우 중요하다.
* enable.auto.commit
    * 백그라운드로 주기적으로 오프셋을 커밋한다.
* auto.offset.reset
    * 카프카에서 초기 오프셋이 없거나 현재 오프셋이 더 이상 존재하지 않은 경우(데이터가 삭제)에 다음 옵션으로 리셋한다.
    * earliest : 가장 초기의 오프셋값으로 설정한다.
    * latest : 가장 마지막의 오프셋값으로 설정한다.
    * none : 이전 오프셋값을 찾지 못하면 에러를 나타낸다.
* fetch.max.bytes
    * 한번에 가져올 수 있는 최대 데이터 사이즈
* request.timeout.ms
    * 요청에 대한 응답을 기다리는 최대 시간
* session.timeout.ms
    * 컨슈머와 브로커사이의 세션 타임 아웃 시간.
    * 브로커가 컨슈머가 살아있는것으로 판단하는 시간(기본값 10초)
    * 만약 컨슈머가 그룹 코디네이터에게 하트비트(heartbeat)를 보내지 않고 session.timeout.ms이 지나면 해당 컨슈머는 종료되거나 장애가 발생한 것으로 판단하고 컨슈머 그룹은 리밸런스(rebalance)를 시도한다.
    * session.timeout.ms은 하트비트 없이 얼마나 오랫동안 컨슈머가 있을 수 있는지를 제어하며, 이 속성은 heartbeat.interval.ms와 밀접한 관련이 있다.
    * 일반적인 경우 두 속성이 함께 수정된다.
    * session.timeout.ms를 기본값보다 낮게 설정하면 실패를 빨리 감지할 수 있지만, 가비지 컬렉션이나 pool 루프를 완료하는 시간이 길어지게 되면 원하지 않게 리밸런스가 일어나기도 한다.
    * 반대로 session.timeout.ms를 높게 설정하면 원하지 않는 리밸런스가 일어날 가능성은 줄지만 실제 오류를 감지하는 데 시간이 오래 걸릴 수 있다.
* heartbeat.interval.ms
    * 그룹 코디네이터에게 얼마나 자주 kafkaConsumer poll() 메소드로 하트비트를 보낼 것인지 조정한다.
    * session.timeout.ms와 밀접한 관계가 있으면 session.timeout.ms보다 낮아야 한다.
    * 일반적으로 3분의 1정도로 설정한다.(기본값은 3초)
* max.poll.records
    * 단일 호출 poll()에 대한 최대 레코드 수를 조정한다.
    * 이 옵션을 통해 애플리케이션이 폴링 루프에서 데이터 양을 조정할 수 있다.
* max.poll.interval.ms
    * 컨슈머가 살아있는지를 체크하기 위해 하트비트를 주기적으로 보내는데, 컨슈머가 계속해서 하트비트만 보내고 실제로 메시지를 가져가지 않는 경우가 있을 수도 있다.
    * 이러한 경우 컨슈머가 무한정 해당 파티션을 점유할 수 없도록 주기적으로 poll을 호출하지 않으면 장애라고 판단하고 컨슈머 그룹에서 제외한 후 다른 컨슈머가 해당 파티션에서 메시지를 가져갈 수 있게 한다.
* auto.commit.interval.ms
    * 주기적으로 오프셋을 커밋하는 시간
* fetch.max.wait.ms
    * fetch.min.bytes에 의해 설정된 데이터보다 적은 경우 요청에 응답을 기다리는 최대 시간

#### 파티션 3개로 구성한 peter-01 토픽과 메시지 순서
* peter-01 토픽은 파티션 수가 3이고 리플리케이션 팩터 옵션은 1이다.
* 컨슈머를 이용해 메시지를 가져오기는 했는데 메시지의 순서가 프로듀서를 통해 보냈던 순서가 아니다.
* 프로듀서가 peter-01 토픽으로 메시지를 a, b, c, d, e 순으로 보냈지만 해당 메시지들은 하나의 파티션에만 순서대로 저장되는 것이 아니라 각각의 파티션별로 메시지가 저장되었다.
* 그리고 컨슈머가 peter-01 토픽에서 메시지를 가져올 때, 컨슈머는 프로듀서가 어떤 순서대로 메시지를 보냈는지 알 수 없다.
* 컨슈머는 오직 파티션의 오프셋 기준으로만 메시지를 가져온다.
* 카프카에서는 토픽의 파티션이 여러 개인 경우, 메시지의 순서는 보장할 수 없다.
* 카프카의 기본 파티션의 개수는 1개이다.
* 카프카의 컨슈머의 메시지 처리 순서는 다음과 같은 방식으로 처리된다.
* 카프카 컨슈머에서의 메시지 순서는 동일한 파티션 내에서는 프로듀서가 생성한 순서와 동일하게 처리하지만, 파티션과 파티션 사이에서는 순서를 보장하지 않는다.

#### 파티션 1개로 구성한 peter-02 토픽과 메시지 순서
* 카프카의 토픽으로 메시지를 보내고 받을 때 메시지의 순서를 정확하게 보장받기 위해서는 토픽의 파티션 수를 1로 지정해 사용해야 한다.
* 프로듀서가 보낸 메시지 순서대로 메시지들은 파티션 0번에 순서대로 저장되어 있고, 메시지 순서에 맞추어 파티션 0번의 오프셋도 순차적으로 증가했다.
* 컨슈머는 파티션의 오프셋 기준으로만 메시지를 가져오기 때문에 프로듀서가 보낸 메시지 순서와 동일하게 메시지를 가져올 수 있는 것이다.
* 카프카를 사용하면서 메시지의 순서를 보장해야 하는 경우에는 토픽의 파티션 수를 1로 설정하면 된다.
* 메시지의 순서는 보장되지만 파티션 수가 하나이기 때문에 분산해서 처리할 수 없고 하나의 컨슈머에서만 처리할 수 있기 때문에 처리량이 높지 않다.
* 즉 처리량이 놓은 카프카를 사용하지만 메시지 순서를 보장해야 한다며 파티션 수를 하나로 만든 토픽을 사용해야 하면, 어느 정도 처리량이 떨어지는 부분은 감안해야 한다.

#### 컨슈머 그룹
* 컨슈머는 카프카 토픽에서 메시지를 읽어오는 역할을 한다.
* 컨슈머 그룹은 하나의 토픽에 여러 컨슈머 그룹이 동시에 접속해 메시지를 가져올 수 있다.
* 이것은 기존의 다른 메시징큐 솔루션에서 동시에 접속해 메시지를 가져가면 큐에서 삭제되어 다른 컨슈머가 가져갈 수 없는 것과는 다른 방식인데 이 방식이 좋은 이유는 최근에 하나의 데이터를 다양한 용도로 사용하는 요구가 많아졌기 때문이다.
* 컨슈머 그룹은 컨슈머를 확장시킬 수도 있다.
* 만약 프로듀서가 토픽에 보내는 메시지 속도가 갑자기 증가해 컨슈머가 메시지를 가져가는 속도보다 빨라지면 어떻게 될까?
* 컨슈머가 처리하지 못한 메시지들이 점점 많아지게 되어, 카프카로 메시지가 들어오는 시간과 그 메시지가 컨슈머에 의해 카프카에서 나가는 시간의 차이는 점점 벌어지게 된다.
* 예를 들어, A 메시지가 프로듀서에 의해 카프카로 들어온 시간이 1시이고, 컨슈머가 메시지를 가져가는 속도가 메시지를 생성하는 속도보다 느리기 때문에 A메시지가 컨슈머에 의해 카프카에서 나가는 시간은 3시라고 가정한다.
* 이런 경우 컨슈머가 메시지를 정해진 시간 내에 모두 처리할 수 없기 때문에 컨슈머를 확장해야 한다.
* 단순하게 컨슈머만 확장한다면, 기존의 컨슈머의 오프셋 정보와 새로 추가된 컨슈머의 오프셋 정보가 뒤섞여 메시지들이 뒤죽박죽될 것이다.
* 그래서 카프카에서는 동일한 토픽에 대해 여러 컨슈머가 메시지를 가져갈 수 있도록 컨슈머 그룹이라는 기능을 제공한다.
* 이러한 기능을 통해 컨슈머는 확장이 용이해지고, 컨슈머의 장애에도 빠른 대처가 가능하다.
* 컨슈머 그룹 아이디(컨슈머 옵션의 group.id)는 컨슈머 그룹 01이라고 설정했고, 컨슈머는 컨슈머 01 하나만 있으며, peter-01 토픽에서 메시지를 가져오고 있다.
* peter-01 토픽은 파티션 수가 3으로 구성된 토픽이고, peter-01의 토픽으로 들어오는 메시지를 컨슈머 01이 가져오고 있다.
* 만약 예기치 않게 갑자기 프로듀서가 peter-01 토픽으로 많은 메시지를 전송한다고 가정해보겠다.
* peter-01 토픽에 너무 많은 메시지들이 들어오게 되면서, 컨슈머가 메시지를 가져가는 속도보다 프로듀서가 메시지를 보내는 속도가 더 빠르다면, peter-01 토픽에는 시간이 지남에 따라 컨슈머가 아직 읽어가지 못한 메시지들이 점점 쌓이게 된다.
* 메시지가 한두 개 쌓이는 것은 아직은 별다른 문제가 되지 않겠지만 지속적으로 쌓이게 된다면 커다란 골칫거리가 될 수도 있다.
* 이런 문제를 해결하기 위해서는 컨슈머를 충분히 확장해야 하며, 카프카에서는 이와 같은 상황을 쉽게 해결할 수 있도록 컨슈머 그룹이라는 기능을 제공한다.
* 기본적으로 컨슈머 그룹 안에서 컨슈머들은 메시지를 가져오고 있는 토픽의 파티션에 대해 소유권을 공유한다.
* 컨슈머 그룹 내 컨슈머의 수가 부족해 프로듀서가 전송하는 메시지를 처리하지 못하는 경우에는 컨슈머를 추가해야 하며, 추가 컨슈머인 컨슈머 02, 03을 실행할 때 동일한 컨슈머 그룹 아이디(group.id는 컨슈머 그룹 01)를 설정하면 하나씩 연결된다.(파티션 3개)
* 동일한 컨슈머 그룹 내 컨슈머가 추가되면 컨슈머 02, 03은 기존 컨슈머 01이 가져가고 있던 파티션1과 2에서 메시지를 가져오기 시작한다.
* 파티션1의 소유권이 컨슈머 01에서 컨슈머 02로 이동했고, 파티션2의 소유권이 컨슈머 01에서 컨슈머 03으로 이동했다.
* 이렇게 소유권이 이동하는 것을 리밸런스(rebalance)라고 한다.
* 이러한 컨슈머 그룹의 리밸런스를 통해 컨슈머 그룹에는 컨슈머를 쉽고 안전하게 추가할 수 있고 제거할 수도 있어 높은 가용성과 확장성을 확보할 수 있다.
* 리밸런스를 하는 동안 일시적으로 컨슈머는 메시지를 가져올 수 없다.
* 그래서 리밸런스가 발생하면 컨슈머 그룹 전체가 일시적으로 사용할 수 없는 단점이 있다.
* 컨슈머 그룹 내에서 리밸런스가 일어나면 토픽의 각 파티션마다 하나의 컨슈머가 연결된다.
* 그리고 리밸런스가 끝나게 되면 컨슈머들은 각자 담당하고 있는 파티션으로부터 메시지를 가져오게 된다.
* 컨슈머 그룹이라는 기능 때문에 간단하게 컨슈머를 추가할 수 있다.
* 그런데 만약 컨슈머를 추가했음에도 불구하고 컨슈머가 가져가는 메시지 수보다 프로듀서에서 보내는 메시지 수가 많아 토픽에 메시지가 점점 쌓이는 상황이라면 어떻게 해야 할까?
* 컨슈머 수를 늘리면 된다고 배웠기 때문에 단순하게 컨슈머의 수를 늘려야 한다는 생각으로 동일한 컨슈머 그룹에 컨슈머 04를 추가했다.
* 열심히 메시지를 가져오기를 해야하는 컨슈머 04가 아무일도 하지 않고 대기만 하고 있다.
* 그리고 컨슈머가 가져오지 못한 메시지들은 peter-01 토픽에 계속 쌓여만 간다.
* 이유는 토픽의 파티션에는 하나의 컨슈머만 연결할 수 있기 때문이다.
* 컨슈머 03, 04가 파티션 2번에 연결하여 메시지를 가져올 수 없는 것이다.
* 결국 토픽의 파티션 수만큼 최대 컨슈머 수가 연결할 수 있다.
* 각각의 파티션에 대해서는 메시지 순서를 보장한다.
* 그런데 만약 하나의 파티션에 두 개의 컨슈머가 연결된다면 안정적으로 메시지 순서를 보장할 수 없게 될 것이다.
* 그래서 카프카에서는 하나의 파티션에 하나의 컨슈머만 연결할 수 있다.
* 토픽의 파티션 수와 동일하게 컨슈머 수를 늘렸는데도 프로듀서가 보내는 메시지의 속도를 따라가지 못한다면 컨슈머만 추가하는 것이 아니라, 토픽의 파티션 수를 늘려주고 컨슈머 수도 같이 늘려줘야 한다.

#### 컨슈머 그룹 내에서 컨슈머 하나가 다운되는 경우
* 컨슈머가 컨슈머 그룹 안에서 멤버로 유지하고 할당된 파티션의 소유권을 유지하는 방법은 하트비트를 보내는 것이다.
* 반대로 생각해보면, 컨슈머가 일정한 주기로 하트비트를 보낸다는 사실은 해당 파티션의 메시지를 잘 처리하고 있다는 것이다.
* 하트비트는 컨슈머가 poll 할 때와 가져간 메시지의 오프셋을 커밋할 때 보내게 된다.
* 만약 컨슈머가 오랫동안 하트비트를 보내지 않으면 세션은 타임아웃되고 해당 컨슈머가 다운되었다고 판단하여 리밸런스가 시작된다.
* 추가된 컨슈머 04가 급작스럽게 다운되었다고 가정해보자.
* 컨슈머 04가 있는 컨슈머는 컨슈머 그룹으로 구성되어 있기 때문에 컨슈머 04가 다운되면, 그룹 내에서 리밸런스가 일어나서 내부적으로 균형을 맞추게 된다.
* 컨슈머 04가 다운되면서, 컨슈머 04가 담당하던 파티션 3을 컨슈머 03이 이어받아 두개의 파티션으로부터 메시지를 가져오는 상황이다.
* 컨슈머 03은 파티션2와 파티션3으로부터 메시지를 가져오고 있지만, 하나의 파티션에 하나의 컨슈머만 연결되었기 때문에 카프카의 룰을 위반한 것은 아니다.
* 하지만 컨슈머 03의 경우에는 두개의 파티션에 대해 메시지를 가져와 처리하다 보니 컨슈머 01, 02과 비교하면 더 많은 메시지를 처리해야 한다.
* 이렇게 약간은 불균형한 상황이 발생할 수도 있지만 전체적인 컨슈머 그룹은 안정적으로 동작함으로써 안정성을 확보할 수 있다.
* 하지만 이런 상황을 지속적으로 내버려두면 일부 메시지를 늦게 가져오는 현상이 발생할 수 있기 때문에 모니터링을 통해 컨슈머의 장애 상황을 인지하고, 새로운 컨슈머를 추가해 정상적인 운영 상태를 만드는 편이 좋다.
* 카프카가 다른 메시지 큐 솔루션과 차별화되는 특징은 하나의 토픽(큐)에 대해 여러 용도로 사용할 수 있다는 점이다.
* 일반적인 메시지 큐 솔루션은 특정 컨슈머가 메시지를 가져가면 큐에서 메시지가 삭제되어 다른 컨슈머는 가져갈 수 없는데 카프카는 컨슈머가 메시지를 가져가도 삭제하지 않는다.
* 이런 특징을 이용해서 하나의 메시지를 여러 컨슈머가 다른 용도로 사용할 수 있도록 시스템을 구성할 수 있다.
* 이것은 데이터 분석이 점점 중요해지는 요즘의 서비스 운영 환경에서 아주 중요한 기술적 장점이라고 할 수 있다.
* 예를 들어 A서비스팀에서 로그 메시지를 peter-01 토픽으로 보내고 A서비스팀은 컨슈머 그룹01를 이용하여 메시지들을 처리하고 있다.
* 얼마 후 B서비스팀에서 신규 프로젝트가 진행되면서 A서비스팀의 로그 메시지들이 필요하게 되었다.
* 이런 경우 B팀이 A팀에게 로그 메시지 전달에 대한 업무 요청을 보냈다.
* A팀은 B팀에게 메시지를 직접 전달해줘도 되지만, 현재 A팀은 카프카의 peter-01 토픽에 메시지를 보내고 있기 때문에 A팀이 카프카 정보와 토픽 정보를 B팀에 알려주면, B팀이 직접 peter-01 토픽에 대해 직접 메시지를 가져갈 수 있다.
* 바로 이러한 경우 peter-01 토픽에 컨슈머 그룹01과 컨슈머 그룹02가 연결되어 메시지를 가져가는 구조이다.
* 이렇게 여러 컨슈머 그룹들이 하나의 토픽에서 메시지를 가져갈 수 있는 이유는 컨슈머 그룹마다 각자의 오프셋을 별도로 관리하기 때문에 하나의 토픽에 두개의 컨슈머 그룹뿐만 아니라 더 많은 컨슈머 그룹이 연결되어도 다른 컨슈머 그룹에게 영향 없이 메시지를 가져갈 수 있기 때문이다.
* 이렇게 여러 개의 컨슈머 그룹이 동시에 하나의 토픽의 메시지를 이용하는 경우, 컨슈머 그룹 아이디는 서로 중복되지 않게 해야 한다.
* 여러 개의 컨슈머 그룹에 대한 동시 사용과 컨슈머 그룹 아이디는 오프셋과 밀접한 관계가 있다.

#### 커밋과 오프셋
* 컨슈머가 poll()을 호출할 때마다 컨슈머 그룹은 카프카에 저장되어 있는 아직 읽지 않은 메시지를 가져온다.
* 이렇게 동작할 수 잇는 것은 컨슈머 그룹이 메시지를 어디까지 가져갔는지 알 수 있기 때문이다.
* 컨슈머 그룹의 컨슈머들은 각각의 파티션에 자신이 가져간 메시지의 위치 정보(오프셋)을 기록하고 있다.
* 각 파티션에 대해 현재 위치를 업데이트하는 동작을 커밋(commit)한다고 한다.
* 카프카는 각 컨슈머 그룹의 파티션별로 오프셋 정보를 저장하기 위한 저장소가 별도로 필요하다.
* 이를 위해 올드 카프카 컨슈머(0.9 이전 버전)는 이 오프셋 정보를 주키퍼에 저장했으며 성능 등의 문제로 뉴 컨슈머에서는 카프카 내에 별도로 내부에서 사용하는 토픽(_consumer_offsets)을 만들고 그 토픽에 오프셋 정보를 저장하고 있다.
* 모든 컨슈머들이 살아있고, 잘 동작하고 있는 동안에는 아무런 영향이 없다.
* 만약 컨슈머가 갑자기 다운되거나 컨슈머 그룹에 새로운 컨슈머가 조인한다면 컨슈머 그룹 내에서 리밸런스가 일어나게 된다.
* 리밸런스가 일어난 후 각각의 컨슈머는 이전에 처리했던 토픽의 파티션이 아닌 다른 새로운 파티션에 할당된다.
* 컨슈머는 새로운 파티션에 대해 가장 최근 커밋되 오프셋을 읽고 그 이후부터 메시지들을 가져오기 시작한다.
* 만약 커밋된 오프셋이 컨슈머가 실제 마지막으로 처리한 오프셋보다 작으면 마지막 처리된 오프셋과 커밋된 오프셋 사이의 메시지는 중복으로 처리되고, 커밋된 오프셋이 컨슈머가 실제 마지막으로 처리한 오프셋보다 크면 마지막 처리된 오프셋과 커밋된 오프셋 사이의 모든 메시지는 누락된다.
* 커밋은 매우 중요하며, 카프카에서는 여러 가지 방법을 제공해준다.

#### 자동 커밋
* 오프셋을 직접 관리하는 방법도 있지만, 각 파티션에 대한 오프셋 정보 관리, 파티션 변경에 대한 관리 등이 매우 번거로울 수 있다.
* 그래서 컨슈머를 다루는 사용자가 오프셋 관리를 직접 하지 않는 방법이 가장 쉬운 방법이다.
* 자동 커밋을 사용하고 싶을 때는 컨슈머 옵션 중 enable.auto.commit = true로 설정하면 5초마다 컨슈머는 poll()를 호출할 때 가장 마지막 오프셋을 커밋한다.
* 5초 주기는 기본값이면, auto.commit.interval.ms 옵션을 통해 조정이 가능하다.
* 컨슈머는 poll 요청할 때마다 커밋할 시간인지 아닌지 체크하게 되고, poll 요청으로 가져온 마지막 오프셋을 커밋한다.

#### 수동 커밋
* 경우에 따라 자동 커밋이 아닌 수동 커밋을 사용해야 하는 경우도 있는데, 이러한 경우는 메시지 처리가 완료될 때까지 메시지를 가져온 것으로 간주되어서는 안 되는 경우에 사용한다.
* 예를 들어, 컨슈머가 메시지를 가져와서 데이터베이스에 메시지를 저장한다고 가정하면
* 만약 자동 커밋을 사용하는 경우라면 자동 커밋의 주기로 인해 poll 하면서 마지막 값의 오프셋으로 자동 커밋이 되었고, 일부 메시지들은 데이터베이스에는 저장하지 못한 상태로 컨슈머 장애가 발생한다면 해당 메시지들은 손실될 수도 있다.
* 이러한 경우를 방지하기 위해 컨슈머가 메시지를 가져오자마자 커밋을 하는 것이 아니라, 데이터베이스에 메시지를 저장한 후 커밋을 해야만 안전하게 메시지를 저장할 수 있다.
* 메시지를 모두 가져온 후 commitSync()를 호출해 커밋한다.
* 수동 커밋은 메시지를 가져온 것으로 간주되는 시점을 자유롭게 조장할 수 있는 장점이 있다.
* 하지만 수동 커밋의 경우에도 중복이 발생할 수 있다.
* 메시지들을 데이터베이스에 저장하는 도중에 실패하게 된다면, 마지막 커밋된 오프셋부터 메시지를 가져오기 때문에 일부 메시지들은 데이터베이스에 중복으로 저장될 수 있다.
* 이렇게 카프카에서 메시지는 한 번씩 전달되지만 장애 등의 이유로 중복이 발생하기 때문에 카프카는 적어도 한번(중복은 있지만 손실은 없다)을 보장한다.

#### 특정 파티션 할당
* 지금까지 컨슈머는 토픽을 서브스크라이브(subscribe)하고, 카프카가 컨슈머 그룹의 컨슈머들에게 직접 파티션을 공평하게 분배하게 했다.
* 하지만 일부의 경우에는 특정 파티션에 대해 세밀하게 제어하기를 원할 수 있다.
1. 키 - 값의 형태로 파티션에 저장되어 있고, 특정 파티션에 대한 메시지들만 가져와야 하는 경우
2. 컨슈머 프로세스가 가용성이 높은 구성인 경우, 카프카가 컨슈머의 실패를 감지하고 재조정할 필요 없이 자동으로 컨슈머 프로세스가 다른 시스템에서 재시작되는 경우
* TopicPartition partition0 = new TopicPartition(topic, 0);
* 수동으로 파티션을 할당해 메시지를 가져올 수도 있다.
* 이러한 방법을 사용하는 경우, 컨슈머 인스턴스마다 컨슈머 그룹 아이디를 서로 다르게 설정해야 한다.
* 만약 동일한 컨슈머 그룹 아이디를 설정하게 되면, 컨슈머마다 할당된 파티션에 대한 오프셋 정보를 서로 공유하기 때문에 종료된 컨슈머의 파티션을 다른 컨슈머가 할당받아 메시지를 이어서 가져가게 되고, 오프셋을 커밋하게 된다.

#### 특정 오프셋부터 메시지 가져오기
* 카프카의 컨슈머 API를 사용하게 되면 메시지 중복 처리 등의 이유로 경우에 따라 오프셋 관리를 수동으로 하는 경우도 있다.
* 이러한 경우에는 수동으로 어디부터 메시지를 읽어올지를 지정해야 하는데 이때는 seek() 메소드를 사용하면 된다.
* consumer.seek(partition0, 2); // 토픽의 파티션 정의 이후 seek(파티션 번호, 오프셋 번호)를 정의하면 컨슈머가 다음 poll()하는 위치를 지정할 수 있게 된다. 2번 오프셋부터 메시지를 가져오게 된다.